{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrieldiasmp/Documents/pasta_gabriel/codigo/master_thesis/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import doubleml as dml\n",
    "import statsmodels.api as sm\n",
    "from linearmodels.iv import IV2SLS\n",
    "from linearmodels.panel.utility import generate_panel_data\n",
    "\n",
    "from doubleml.datasets import (\n",
    "    make_plr_CCDDHNR2018, #Linear Regression\n",
    "    make_pliv_CHS2015, #Instrumental variables\n",
    "    make_did_SZ2020 #Panel Data\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Main imports\n",
    "from econml.panel.dml import DynamicDML\n",
    "#from econml.tests.dgp import DynamicPanelDGP, add_vlines\n",
    "\n",
    "# Helper imports\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, LogisticRegressionCV, MultiTaskLassoCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import doubleml as dml\n",
    "from doubleml.datasets import make_pliv_CHS2015\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ___  ____  ____  ____  ____ ©\n",
      " /__    /   ____/   /   ____/      17.0\n",
      "___/   /   /___/   /   /___/       SE—Standard Edition\n",
      "\n",
      " Statistics and Data Science       Copyright 1985-2021 StataCorp LLC\n",
      "                                   StataCorp\n",
      "                                   4905 Lakeway Drive\n",
      "                                   College Station, Texas 77845 USA\n",
      "                                   800-STATA-PC        https://www.stata.com\n",
      "                                   979-696-4600        stata@stata.com\n",
      "\n",
      "Stata license: Unlimited-user network, expiring 15 Oct 2024\n",
      "Serial number: 401809305874\n",
      "  Licensed to: Gabriel Dias Medeiros Pereira\n",
      "               ISEG\n",
      "\n",
      "Notes:\n",
      "      1. Unicode is supported; see help unicode_advice.\n",
      "      2. Maximum number of variables is set to 5,000; see help set_maxvar.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Applications/Stata/utilities')\n",
    "from pystata import config\n",
    "config.init('se')\n",
    "\n",
    "from pystata import stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acemoglu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"/Users/gabrieldiasmp/Documents/pasta_gabriel/codigo/master_thesis/data/xcountry_data.dta\", convert_dates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>africa</th>\n",
       "      <th>lat_abst</th>\n",
       "      <th>asia</th>\n",
       "      <th>baseco</th>\n",
       "      <th>f_brit</th>\n",
       "      <th>f_french</th>\n",
       "      <th>temp1</th>\n",
       "      <th>temp2</th>\n",
       "      <th>temp3</th>\n",
       "      <th>...</th>\n",
       "      <th>Yrsmis60</th>\n",
       "      <th>ruleoflaw</th>\n",
       "      <th>protmiss</th>\n",
       "      <th>dummy_dennis</th>\n",
       "      <th>neoeuropes</th>\n",
       "      <th>logpgdp05</th>\n",
       "      <th>tyr05_n</th>\n",
       "      <th>lcapped</th>\n",
       "      <th>prienr1870</th>\n",
       "      <th>prienr1940</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>0.473416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.199643</td>\n",
       "      <td>2.169000</td>\n",
       "      <td>5.521461</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.486717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.290390</td>\n",
       "      <td>8.870034</td>\n",
       "      <td>4.232656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.038857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.395712</td>\n",
       "      <td>11.943940</td>\n",
       "      <td>2.145931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BFA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.914727</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>5.521461</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BGD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.066095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.060130</td>\n",
       "      <td>4.186033</td>\n",
       "      <td>4.268438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.018649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.658870</td>\n",
       "      <td>13.190048</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>VEN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>0.435332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.202758</td>\n",
       "      <td>5.800205</td>\n",
       "      <td>4.357990</td>\n",
       "      <td>1.6</td>\n",
       "      <td>26.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>VNM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.012681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.678452</td>\n",
       "      <td>4.928604</td>\n",
       "      <td>4.941642</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ZAF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.524327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.059149</td>\n",
       "      <td>7.743558</td>\n",
       "      <td>2.740840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ZAR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>1.044340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.567176</td>\n",
       "      <td>3.010000</td>\n",
       "      <td>5.480639</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   code  africa  lat_abst  asia  baseco  f_brit  f_french  temp1  temp2  \\\n",
       "0   AGO     1.0  0.136667   0.0     1.0     0.0       0.0   26.0   28.0   \n",
       "1   ARG     0.0  0.377778   0.0     1.0     0.0       0.0   17.0   25.0   \n",
       "2   AUS     0.0  0.300000   0.0     1.0     1.0       0.0   17.0   18.0   \n",
       "3   BFA     1.0  0.144444   0.0     1.0     0.0       1.0   29.0   38.0   \n",
       "4   BGD     0.0  0.266667   1.0     1.0     1.0       0.0   25.0   29.0   \n",
       "..  ...     ...       ...   ...     ...     ...       ...    ...    ...   \n",
       "59  USA     0.0  0.422222   0.0     1.0     1.0       0.0   27.0   32.0   \n",
       "60  VEN     0.0  0.088889   0.0     1.0     0.0       0.0   20.0   28.0   \n",
       "61  VNM     0.0  0.177778   1.0     1.0     0.0       1.0   25.0   33.0   \n",
       "62  ZAF     1.0  0.322222   0.0     1.0     1.0       0.0   19.0   29.0   \n",
       "63  ZAR     1.0  0.000000   0.0     1.0     0.0       0.0   25.0   32.0   \n",
       "\n",
       "    temp3  ...  Yrsmis60  ruleoflaw  protmiss  dummy_dennis  neoeuropes  \\\n",
       "0    37.0  ...      82.0      -1.22  0.473416           0.0         0.0   \n",
       "1    40.0  ...     124.0      -0.67  0.486717           0.0         0.0   \n",
       "2    43.0  ...       NaN       1.74  0.038857           1.0         1.0   \n",
       "3    48.0  ...      37.0      -0.22  0.039800           0.0         0.0   \n",
       "4    42.0  ...     165.0      -0.76  0.066095           0.0         0.0   \n",
       "..    ...  ...       ...        ...       ...           ...         ...   \n",
       "59   37.0  ...       NaN       1.55  0.018649           1.0         1.0   \n",
       "60   33.0  ...      77.0      -1.59  0.435332           0.0         0.0   \n",
       "61   43.0  ...      49.0      -0.45  0.012681           0.0         0.0   \n",
       "62   39.0  ...     223.0       0.09  2.524327           0.0         0.0   \n",
       "63   36.0  ...      82.0      -1.63  1.044340           0.0         0.0   \n",
       "\n",
       "    logpgdp05    tyr05_n   lcapped  prienr1870  prienr1940  \n",
       "0    8.199643   2.169000  5.521461         0.1    0.600000  \n",
       "1    9.290390   8.870034  4.232656         NaN         NaN  \n",
       "2   10.395712  11.943940  2.145931         NaN         NaN  \n",
       "3    6.914727   0.728000  5.521461         0.1    2.000000  \n",
       "4    7.060130   4.186033  4.268438         NaN         NaN  \n",
       "..        ...        ...       ...         ...         ...  \n",
       "59  10.658870  13.190048  2.708050         NaN         NaN  \n",
       "60   9.202758   5.800205  4.357990         1.6   26.700001  \n",
       "61   7.678452   4.928604  4.941642         0.1   10.800000  \n",
       "62   9.059149   7.743558  2.740840         NaN         NaN  \n",
       "63   5.567176   3.010000  5.480639         0.1    8.500000  \n",
       "\n",
       "[64 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['code', 'africa', 'lat_abst', 'asia', 'baseco', 'f_brit', 'f_french',\n",
       "       'temp1', 'temp2', 'temp3', 'temp4', 'temp5', 'humid1', 'humid2',\n",
       "       'humid3', 'humid4', 'malfal94', 'lpd1500s', 'america', 'prienr1900',\n",
       "       'cath1900', 'prot1900', 'musl1900', 'Yrsmis60', 'ruleoflaw', 'protmiss',\n",
       "       'dummy_dennis', 'neoeuropes', 'logpgdp05', 'tyr05_n', 'lcapped',\n",
       "       'prienr1870', 'prienr1940'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stata.pdataframe_to_data(df, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = RandomForestRegressor(n_estimators=100, max_features=20, max_depth=5, min_samples_leaf=2)\n",
    "ml_l = clone(learner)\n",
    "ml_m = clone(learner)\n",
    "ml_r = clone(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col='logpgdp05'\n",
    "d_cols=['ruleoflaw', \"tyr05_n\"]\n",
    "z_cols=[\"prienr1900\", \"protmiss\", \"lcapped\", \"lpd1500s\"]\n",
    "x_cols=[col_x for col_x in df.columns if col_x not in [y_col]+d_cols+z_cols+[\"code\", \"Yrsmis60\", \"prienr1870\",\"prienr1940\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [y_col]+d_cols+z_cols+x_cols\n",
    "df_institutions = df[cols].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dml_data = dml.DoubleMLData(\n",
    "    df_institutions, y_col=y_col, d_cols=d_cols,\n",
    "    z_cols=z_cols, x_cols=x_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               coef   std err         t         P>|t|     2.5 %    97.5 %\n",
      "ruleoflaw  1.089580  0.212876  5.118377  3.081769e-07  0.672350  1.506809\n",
      "tyr05_n    0.206315  0.075541  2.731159  6.311197e-03  0.058257  0.354374\n"
     ]
    }
   ],
   "source": [
    "dml_iivm_obj = dml.DoubleMLPLIV(obj_dml_data, ml_l, ml_m, ml_r)\n",
    "print(dml_iivm_obj.fit().summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angrist, Kluger (2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_immigration = pd.read_sas(\"/Users/gabrieldiasmp/Documents/pasta_gabriel/codigo/master_thesis/data/rsa8399n.sas7bdat\")\n",
    "df_immigration = pd.read_stata(\"../data/df_immigration.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration['year_datetime'] = df_immigration['year'][:4]\n",
    "\n",
    "def convert_to_datetime(period):\n",
    "    year = int(period[:4])\n",
    "    return pd.to_datetime(f\"{year}\", format='%Y')\n",
    "\n",
    "# Apply the function to the 'period' column\n",
    "df_immigration['year_datetime'] = df_immigration['year'].apply(convert_to_datetime)\n",
    "df_immigration['year_datetime'] = df_immigration['year_datetime'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_barent = pd.read_sas(\"../data/bar_ent.sas7bdat\")\n",
    "df_barent.columns = [\"country\", \"bar_ent\"]\n",
    "df_barent['country'] = df_barent['country'].apply(lambda x: x.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration = pd.merge(df_immigration, df_barent, on='country', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gdp_gr', 'urate', 'lag_gdp', 'schengen', 'p96schen']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macroeconomic_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SAS macros as a dictionary\n",
    "sas_macros = {\n",
    "    'non_eu_immigration_share':['lnf_lf1'],\n",
    "    'years': ['lneu_lf1', 'd84', 'd85', 'd86', 'd87', 'd88', 'd89', 'd90', 'd91', 'd92', 'd93', 'd94', 'd95', 'd96', 'd97', 'd98', 'd99'], #\n",
    "    'country': ['be', 'dk', 'de91', 'de_91', 'gr', 'es', 'fr', 'ie', 'it', 'lu', 'nl', 'at', 'pt', 'fi', 'se', 'uk', 'no', 'is', 'ch'],\n",
    "    'ctrends': ['trendbe', 'trendk', 'trende91', 'trend_91', 'trendgr', 'trendes', 'trendfr', 'trendie', 'trendit',\n",
    "                'trendlu', 'trendnl', 'trendat', 'trendpt', 'trendfi', 'trendse', 'trenduk', 'trendno', 'trendis',\n",
    "                'trendch'],\n",
    "    'inst1': ['nbospr1', 'nowarpr1', 'nkospr1'],\n",
    "    \"institutions\": ['emp_prot','lab_stan','rep_rate'],\n",
    "    'population_variables': df_immigration.iloc[:, 147:171].columns.tolist(),\n",
    "    'macroeconomic_variables': df_immigration.iloc[:, 277:280].columns.tolist()+['schengen', 'p96schen']\n",
    "}\n",
    "\n",
    "# Unpack the dictionary into variables\n",
    "non_eu_immigration_share, years, country, ctrends, inst1, institutions, population_variables, macroeconomic_variables = sas_macros.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration[\"emp_prot\"]=df_immigration[\"emp_prot\"]-13\n",
    "df_immigration[\"lab_stan\"]=(df_immigration[\"lab_stan\"]-5)/1.9518\n",
    "df_immigration[\"rep_rate\"]=(df_immigration[\"rep_rate\"]-63)/17.70741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration[\"ep\"]=(df_immigration[\"bar_ent\"]-1.715)/.604373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CHANGING THE ORIGINAL SPECIFICATION OF THE MODEL: If i want to replicate the original, i shouldn't go to percentages\n",
    "\n",
    "# df_immigration['lne_p'] = np.exp(df_immigration['lne_p'])\n",
    "# df_immigration['lneu_lf1'] = np.exp(df_immigration['lneu_lf1'])\n",
    "# df_immigration[non_eu_immigration_share] = np.exp(df_immigration[non_eu_immigration_share])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration['NEU_ep'] = df_immigration['lnf_lf1'] * df_immigration['ep']\n",
    "df_immigration['NEU_ls'] = df_immigration['lnf_lf1'] * df_immigration['lab_stan']\n",
    "df_immigration['NEU_rr'] = df_immigration['lnf_lf1'] * df_immigration['rep_rate']\n",
    "\n",
    "df_immigration['nbos_ep'] = df_immigration['nbospr1'] * df_immigration['ep']\n",
    "df_immigration['nowar_ep'] = df_immigration['nowarpr1'] * df_immigration['ep']\n",
    "df_immigration['nkos_ep'] = df_immigration['nkospr1'] * df_immigration['ep']\n",
    "\n",
    "df_immigration['nbos_ls'] = df_immigration['nbospr1'] * df_immigration['lab_stan']\n",
    "df_immigration['nowar_ls'] = df_immigration['nowarpr1'] * df_immigration['lab_stan']\n",
    "df_immigration['nkos_ls'] = df_immigration['nkospr1'] * df_immigration['lab_stan']\n",
    "\n",
    "df_immigration['nbos_rr'] = df_immigration['nbospr1'] * df_immigration['rep_rate']\n",
    "df_immigration['nowar_rr'] = df_immigration['nowarpr1'] * df_immigration['rep_rate']\n",
    "df_immigration['nkos_rr'] = df_immigration['nkospr1'] * df_immigration['rep_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SAS macros as a dictionary\n",
    "sas_macros = {\n",
    "    'first_instruments': ['nbospr1', 'nowarpr1', 'nkospr1'],\n",
    "    'instls': ['nbos_ls', 'nowar_ls', 'nkos_ls'],\n",
    "    'instrr': ['nbos_rr', 'nowar_rr', 'nkos_rr'],\n",
    "    'instlsrr': ['nbos_ls', 'nowar_ls', 'nkos_ls', 'nbos_rr', 'nowar_rr', 'nkos_rr'],\n",
    "    'inst1b': ['nbosds12', 'noward12', 'nkosds12', 'nbos_ep', 'nowar_ep', 'nkos_ep'],\n",
    "    'inst2b': ['nbosds12', 'noward12', 'nkosds12', 'nbos_ep', 'nowar_ep', 'nkos_ep', 'nbos_ls', 'nowar_ls', 'nkos_ls'],\n",
    "    'inst3b': ['nbosds12', 'noward12', 'nkosds12', 'nbos_ep', 'nowar_ep', 'nkos_ep','nbos_ls', 'nowar_ls', 'nkos_ls', 'nbos_rr', 'nowar_rr', 'nkos_rr'] # \n",
    "}\n",
    "\n",
    "# Unpack the dictionary into variables\n",
    "first_instruments, instls, instrr, instlsrr, inst1b, inst2b, inst3b = sas_macros.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stata code:\n",
    "\n",
    "https://economics.mit.edu/sites/default/files/inline-files/t4new.do\n",
    "\n",
    "/* Generate instruments using distance from Pristina */\n",
    "gen nowarpr1=nowar*Sardis1/1000\n",
    "gen nbospr1=nwbosnia*Sardis1/1000\n",
    "gen nkospr1=nwkosovo*prdis1/1000\n",
    "\n",
    "gen nowarpr2=nowar*Sardis2/1000\n",
    "gen nbospr2=nwbosnia*Sardis2/1000\n",
    "gen nkospr2=nwkosovo*prdis2/1000\n",
    "\n",
    "/* Generate pre-period spec. check dummy */\n",
    "gen pre90=(prdis1*(trend>=1988 & trend<=1999))/1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAS code\n",
    "\n",
    " %macro years; lneu_lf1 d84 d85 d86 d87 d88 d89 d90 d91 d92 d93 d94 d95 d96 d97 d98 d99 %mend;\n",
    " %macro country; be dk de91 de_91 gr es fr ie it lu nl at pt fi se uk no is ch %mend;\n",
    " %macro ctrends; trendbe trendk trende91 trend_91 trendgr trendes trendfr trendie trendit\n",
    "                 trendlu trendnl trendat trendpt trendfi trendse trenduk trendno trendis\n",
    "                 trendch %mend;\n",
    " %macro inst1; nbospr1 nowarpr1 nkospr1 %mend;\n",
    "\n",
    " emp_prot=emp_prot-13;\n",
    " lab_stan=(lab_stan-5)/1.9518;\n",
    " rep_rate=(rep_rate-63)/17.70741;\n",
    "\n",
    " ep=(bar_ent-1.715)/.604373;\n",
    "\n",
    " NEU_ep=lnf_lf1*ep;\n",
    " NEU_ls=lnf_lf1*lab_stan;\n",
    " NEU_rr=lnf_lf1*rep_rate;\n",
    "\n",
    " nbos_ep=nbospr1*ep;\n",
    " nowar_ep=nowarpr1*ep;\n",
    " nkos_ep=nkospr1*ep;\n",
    " nbos_ls=nbospr1*lab_stan;\n",
    " nowar_ls=nowarpr1*lab_stan;\n",
    " nkos_ls=nkospr1*lab_stan;\n",
    " nbos_rr=nbospr1*rep_rate;\n",
    " nowar_rr=nowarpr1*rep_rate;\n",
    " nkos_rr=nkospr1*rep_rate;\n",
    "\n",
    " %macro instls; %inst1 nbos_ls nowar_ls nkos_ls %mend;\n",
    " %macro instrr; %inst1 nbos_rr nowar_rr nkos_rr %mend;\n",
    " %macro instlsrr; %inst1 nbos_ls nowar_ls nkos_ls nbos_rr nowar_rr nkos_rr %mend;\n",
    " %macro inst1b; nbosds12 noward12 nkosds12 nbos_ep nowar_ep nkos_ep %mend;\n",
    " %macro inst2b; %inst1b nbos_ls nowar_ls nkos_ls %mend;\n",
    " %macro inst3b; %inst2b nbos_rr nowar_rr nkos_rr %mend;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform regressions\n",
    "\n",
    "For more info: https://economics.mit.edu/sites/default/files/inline-files/t6new.sas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OLS, LS, all men with country and time effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************************************************;\n",
    "# *            Labor Standards                     *;\n",
    "# **************************************************;\n",
    "\n",
    "# ******************Men**************************\n",
    "\n",
    "# Filter the data\n",
    "data_filtered = df_immigration[(df_immigration['is'] == 0) & (df_immigration['dman'] == 1)]\n",
    "data_filtered = data_filtered[['lne_p'] + ['lnf_lf1', 'NEU_ls', 'dold'] + years + country].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lne_p</th>\n",
       "      <th>lnf_lf1</th>\n",
       "      <th>NEU_ls</th>\n",
       "      <th>dold</th>\n",
       "      <th>lneu_lf1</th>\n",
       "      <th>d84</th>\n",
       "      <th>d85</th>\n",
       "      <th>d86</th>\n",
       "      <th>d87</th>\n",
       "      <th>d88</th>\n",
       "      <th>...</th>\n",
       "      <th>lu</th>\n",
       "      <th>nl</th>\n",
       "      <th>at</th>\n",
       "      <th>pt</th>\n",
       "      <th>fi</th>\n",
       "      <th>se</th>\n",
       "      <th>uk</th>\n",
       "      <th>no</th>\n",
       "      <th>is</th>\n",
       "      <th>ch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.143954</td>\n",
       "      <td>-2.468772</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.499256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.160672</td>\n",
       "      <td>-2.468205</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.409521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.150230</td>\n",
       "      <td>-2.424959</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.398050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.140117</td>\n",
       "      <td>-2.476395</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.208497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.133083</td>\n",
       "      <td>-2.502741</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.240854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-0.214826</td>\n",
       "      <td>-3.830824</td>\n",
       "      <td>9.813567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.142182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>-0.209440</td>\n",
       "      <td>-3.825722</td>\n",
       "      <td>9.800498</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.168144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>-0.208251</td>\n",
       "      <td>-3.760098</td>\n",
       "      <td>9.632385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.155677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>-0.199560</td>\n",
       "      <td>-3.681319</td>\n",
       "      <td>9.430574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.061137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>-0.190679</td>\n",
       "      <td>-3.734808</td>\n",
       "      <td>9.567600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.085863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lne_p   lnf_lf1    NEU_ls  dold  lneu_lf1  d84  d85  d86  d87  d88  \\\n",
       "0   -0.143954 -2.468772 -0.000000   0.0 -4.499256  0.0  0.0  0.0  0.0  0.0   \n",
       "1   -0.160672 -2.468205 -0.000000   0.0 -4.409521  0.0  0.0  0.0  0.0  0.0   \n",
       "2   -0.150230 -2.424959 -0.000000   0.0 -4.398050  0.0  0.0  0.0  0.0  0.0   \n",
       "3   -0.140117 -2.476395 -0.000000   0.0 -4.208497  0.0  0.0  0.0  0.0  0.0   \n",
       "4   -0.133083 -2.502741 -0.000000   0.0 -4.240854  0.0  0.0  0.0  0.0  0.0   \n",
       "..        ...       ...       ...   ...       ...  ...  ...  ...  ...  ...   \n",
       "825 -0.214826 -3.830824  9.813567   1.0 -4.142182  0.0  0.0  0.0  0.0  0.0   \n",
       "826 -0.209440 -3.825722  9.800498   1.0 -4.168144  0.0  0.0  0.0  0.0  0.0   \n",
       "827 -0.208251 -3.760098  9.632385   1.0 -4.155677  0.0  0.0  0.0  0.0  0.0   \n",
       "828 -0.199560 -3.681319  9.430574   1.0 -4.061137  0.0  0.0  0.0  0.0  0.0   \n",
       "829 -0.190679 -3.734808  9.567600   1.0 -4.085863  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     ...   lu   nl   at   pt   fi   se   uk   no   is   ch  \n",
       "0    ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1    ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2    ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3    ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4    ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "825  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "826  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "827  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "828  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "829  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[334 rows x 40 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered[['lne_p'] + ['lnf_lf1', 'NEU_ls', 'dold'] + years + country].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lne_p   R-squared:                       0.704\n",
      "Model:                            OLS   Adj. R-squared:                  0.669\n",
      "Method:                 Least Squares   F-statistic:                     20.20\n",
      "Date:                Wed, 17 Apr 2024   Prob (F-statistic):           1.44e-59\n",
      "Time:                        12:00:06   Log-Likelihood:                 669.81\n",
      "No. Observations:                 334   AIC:                            -1268.\n",
      "Df Residuals:                     298   BIC:                            -1130.\n",
      "Df Model:                          35                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0933      0.049     -1.897      0.059      -0.190       0.003\n",
      "lnf_lf1       -0.0270      0.010     -2.659      0.008      -0.047      -0.007\n",
      "NEU_ls        -0.0149      0.007     -2.257      0.025      -0.028      -0.002\n",
      "dold           0.0103      0.004      2.729      0.007       0.003       0.018\n",
      "lneu_lf1       0.0440      0.013      3.276      0.001       0.018       0.070\n",
      "d84           -0.0003      0.014     -0.019      0.985      -0.028       0.028\n",
      "d85           -0.0098      0.014     -0.719      0.473      -0.037       0.017\n",
      "d86           -0.0012      0.014     -0.081      0.935      -0.029       0.027\n",
      "d87           -0.0083      0.013     -0.622      0.534      -0.035       0.018\n",
      "d88           -0.0041      0.013     -0.303      0.762      -0.030       0.022\n",
      "d89            0.0047      0.013      0.356      0.722      -0.021       0.031\n",
      "d90            0.0131      0.013      0.984      0.326      -0.013       0.039\n",
      "d91            0.0094      0.013      0.722      0.471      -0.016       0.035\n",
      "d92           -0.0070      0.013     -0.541      0.589      -0.033       0.019\n",
      "d93           -0.0235      0.013     -1.836      0.067      -0.049       0.002\n",
      "d94           -0.0256      0.013     -1.992      0.047      -0.051      -0.000\n",
      "d95           -0.0253      0.012     -2.067      0.040      -0.049      -0.001\n",
      "d96           -0.0158      0.012     -1.270      0.205      -0.040       0.009\n",
      "d97           -0.0135      0.012     -1.094      0.275      -0.038       0.011\n",
      "d98           -0.0039      0.012     -0.314      0.754      -0.028       0.020\n",
      "d99            0.0088      0.012      0.711      0.477      -0.016       0.033\n",
      "be            -0.0643      0.020     -3.293      0.001      -0.103      -0.026\n",
      "dk             0.1327      0.045      2.965      0.003       0.045       0.221\n",
      "de91          -0.0217      0.017     -1.252      0.212      -0.056       0.012\n",
      "de_91         -0.0178      0.019     -0.942      0.347      -0.055       0.019\n",
      "gr         -4.232e-17   1.23e-17     -3.429      0.001   -6.66e-17    -1.8e-17\n",
      "es            -0.1687      0.045     -3.786      0.000      -0.256      -0.081\n",
      "fr            -0.0575      0.017     -3.345      0.001      -0.091      -0.024\n",
      "ie            -0.0945      0.022     -4.204      0.000      -0.139      -0.050\n",
      "it            -0.0871      0.044     -1.977      0.049      -0.174      -0.000\n",
      "lu         -2.771e-18   2.75e-18     -1.006      0.315   -8.19e-18    2.65e-18\n",
      "nl             0.0066      0.007      0.962      0.337      -0.007       0.020\n",
      "at             0.0493      0.017      2.851      0.005       0.015       0.083\n",
      "pt             0.0919      0.028      3.237      0.001       0.036       0.148\n",
      "fi            -0.0341      0.032     -1.067      0.287      -0.097       0.029\n",
      "se            -0.0746      0.028     -2.658      0.008      -0.130      -0.019\n",
      "uk             0.1330      0.058      2.277      0.023       0.018       0.248\n",
      "no             0.0467      0.012      3.922      0.000       0.023       0.070\n",
      "is                  0          0        nan        nan           0           0\n",
      "ch             0.0668      0.032      2.075      0.039       0.003       0.130\n",
      "==============================================================================\n",
      "Omnibus:                        0.438   Durbin-Watson:                   0.578\n",
      "Prob(Omnibus):                  0.803   Jarque-Bera (JB):                0.296\n",
      "Skew:                          -0.064   Prob(JB):                        0.863\n",
      "Kurtosis:                       3.068   Cond. No.                     2.59e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.97e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Define the independent variables\n",
    "X = data_filtered[['lnf_lf1', 'NEU_ls', 'dold'] + years + country]\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "y = data_filtered['lne_p']\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OLS, BE-LS-RR, all men with country and time effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********************************************;\n",
    "# *        Barriers, Lab. Stan., Rep. Rate      *;\n",
    "# ***********************************************;\n",
    "\n",
    "# ******************Men**************************;\n",
    "\n",
    "# Filter the data\n",
    "data_filtered = df_immigration[(df_immigration['is'] == 0) & (df_immigration['dman'] == 1) & (df_immigration['dold'] == 0)]\n",
    "data_filtered = data_filtered[['lne_p'] + ['lnf_lf1', 'NEU_ls', 'NEU_ep', 'NEU_rr'] + years + country].dropna() #, 'dold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334, 42)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lne_p   R-squared:                       0.866\n",
      "Model:                            OLS   Adj. R-squared:                  0.828\n",
      "Method:                 Least Squares   F-statistic:                     521.5\n",
      "Date:                Wed, 24 Apr 2024   Prob (F-statistic):          1.43e-124\n",
      "Time:                        09:43:26   Log-Likelihood:                 377.74\n",
      "No. Observations:                 167   AIC:                            -681.5\n",
      "Df Residuals:                     130   BIC:                            -566.1\n",
      "Df Model:                          36                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1241      0.068     -1.821      0.069      -0.258       0.009\n",
      "lnf_lf1       -0.0526      0.015     -3.494      0.000      -0.082      -0.023\n",
      "NEU_ls        -0.0055      0.015     -0.361      0.718      -0.035       0.024\n",
      "NEU_ep        -0.0178      0.019     -0.918      0.358      -0.056       0.020\n",
      "NEU_rr        -0.0172      0.011     -1.514      0.130      -0.039       0.005\n",
      "lneu_lf1       0.0620      0.019      3.341      0.001       0.026       0.098\n",
      "d84            0.0017      0.023      0.075      0.940      -0.043       0.046\n",
      "d85           -0.0062      0.023     -0.266      0.790      -0.052       0.040\n",
      "d86            0.0085      0.023      0.375      0.708      -0.036       0.053\n",
      "d87            0.0027      0.022      0.124      0.901      -0.040       0.045\n",
      "d88            0.0046      0.022      0.214      0.830      -0.038       0.047\n",
      "d89            0.0185      0.022      0.846      0.398      -0.024       0.061\n",
      "d90            0.0281      0.021      1.314      0.189      -0.014       0.070\n",
      "d91            0.0180      0.022      0.803      0.422      -0.026       0.062\n",
      "d92           -0.0017      0.023     -0.077      0.939      -0.046       0.043\n",
      "d93           -0.0220      0.022     -0.981      0.327      -0.066       0.022\n",
      "d94           -0.0234      0.022     -1.087      0.277      -0.066       0.019\n",
      "d95           -0.0204      0.022     -0.932      0.352      -0.063       0.023\n",
      "d96           -0.0080      0.022     -0.372      0.710      -0.050       0.034\n",
      "d97           -0.0038      0.022     -0.172      0.863      -0.047       0.040\n",
      "d98            0.0107      0.022      0.477      0.634      -0.033       0.054\n",
      "d99            0.0290      0.023      1.277      0.202      -0.016       0.073\n",
      "be            -0.1577      0.121     -1.300      0.194      -0.396       0.080\n",
      "dk          9.011e-05      0.121      0.001      0.999      -0.237       0.238\n",
      "de91          -0.0141      0.019     -0.743      0.458      -0.051       0.023\n",
      "de_91         -0.0476      0.020     -2.385      0.017      -0.087      -0.008\n",
      "gr          8.229e-17   3.98e-16      0.207      0.836   -6.98e-16    8.63e-16\n",
      "es            -0.2308      0.090     -2.568      0.010      -0.407      -0.055\n",
      "fr            -0.1123      0.073     -1.532      0.126      -0.256       0.031\n",
      "ie             0.0492      0.123      0.399      0.690      -0.192       0.291\n",
      "it            -0.0005      0.104     -0.004      0.997      -0.204       0.203\n",
      "lu          6.019e-16   3.05e-16      1.971      0.049    3.25e-18     1.2e-15\n",
      "nl             0.0343      0.041      0.833      0.405      -0.046       0.115\n",
      "at             0.1563      0.043      3.599      0.000       0.071       0.241\n",
      "pt             0.0930      0.044      2.112      0.035       0.007       0.179\n",
      "fi            -0.0275      0.061     -0.448      0.654      -0.148       0.093\n",
      "se            -0.1485      0.055     -2.681      0.007      -0.257      -0.040\n",
      "uk             0.2802      0.103      2.711      0.007       0.078       0.483\n",
      "no             0.0676      0.056      1.202      0.229      -0.043       0.178\n",
      "is                  0          0        nan        nan           0           0\n",
      "ch            -0.0658      0.095     -0.693      0.489      -0.252       0.120\n",
      "==============================================================================\n",
      "Omnibus:                        0.196   Durbin-Watson:                   0.941\n",
      "Prob(Omnibus):                  0.907   Jarque-Bera (JB):                0.314\n",
      "Skew:                           0.070   Prob(JB):                        0.855\n",
      "Kurtosis:                       2.841   Cond. No.                     1.06e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
      "[2] The smallest eigenvalue is 6.2e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance of constraints does not have full rank. The number of constraints is 40, but rank is 37\n"
     ]
    }
   ],
   "source": [
    "# Define the independent variables\n",
    "X = data_filtered[['lnf_lf1', 'NEU_ls', 'NEU_ep', 'NEU_rr'] + years + country] #, 'dold']\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "y = data_filtered['lne_p']\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit(cov_type=\"HC1\")\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple OLS estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_immigration = ['lnf_lf1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "data_filtered = df_immigration[(df_immigration['is'] == 0) & (df_immigration['dman'] == 1) & (df_immigration['dold'] == 0)]\n",
    "data_filtered = data_filtered[['lne_p'] + non_eu_immigration + first_instruments + years + country].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 41)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lne_p   R-squared:                       0.870\n",
      "Model:                            OLS   Adj. R-squared:                  0.841\n",
      "Method:                 Least Squares   F-statistic:                     847.8\n",
      "Date:                Wed, 24 Apr 2024   Prob (F-statistic):          1.67e-169\n",
      "Time:                        09:31:32   Log-Likelihood:                 466.35\n",
      "No. Observations:                 202   AIC:                            -856.7\n",
      "Df Residuals:                     164   BIC:                            -731.0\n",
      "Df Model:                          37                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1220      0.059     -2.072      0.038      -0.237      -0.007\n",
      "lneu_lf1       0.0131      0.014      0.925      0.355      -0.015       0.041\n",
      "nbospr1        0.0357      0.019      1.915      0.055      -0.001       0.072\n",
      "nowarpr1       0.0694      0.020      3.475      0.001       0.030       0.109\n",
      "nkospr1        0.0986      0.019      5.189      0.000       0.061       0.136\n",
      "d84            0.0025      0.018      0.138      0.890      -0.033       0.038\n",
      "d85           -0.0051      0.019     -0.267      0.789      -0.043       0.033\n",
      "d86            0.0088      0.018      0.494      0.622      -0.026       0.044\n",
      "d87            0.0023      0.017      0.132      0.895      -0.032       0.036\n",
      "d88            0.0059      0.018      0.336      0.737      -0.028       0.040\n",
      "d89            0.0115      0.019      0.618      0.537      -0.025       0.048\n",
      "d90            0.0154      0.020      0.780      0.435      -0.023       0.054\n",
      "d91           -0.0192      0.023     -0.842      0.400      -0.064       0.025\n",
      "d92           -0.0406      0.022     -1.868      0.062      -0.083       0.002\n",
      "d93           -0.0608      0.022     -2.733      0.006      -0.104      -0.017\n",
      "d94           -0.0690      0.022     -3.082      0.002      -0.113      -0.025\n",
      "d95           -0.0620      0.022     -2.777      0.005      -0.106      -0.018\n",
      "d96           -0.0858      0.023     -3.752      0.000      -0.131      -0.041\n",
      "d97           -0.0785      0.023     -3.485      0.000      -0.123      -0.034\n",
      "d98           -0.0982      0.025     -3.989      0.000      -0.146      -0.050\n",
      "d99           -0.0867      0.023     -3.706      0.000      -0.133      -0.041\n",
      "be            -0.0194      0.018     -1.058      0.290      -0.055       0.016\n",
      "dk             0.0318      0.012      2.617      0.009       0.008       0.056\n",
      "de91           0.0359      0.009      4.078      0.000       0.019       0.053\n",
      "de_91         -0.0146      0.014     -1.060      0.289      -0.041       0.012\n",
      "gr             0.0434      0.033      1.313      0.189      -0.021       0.108\n",
      "es            -0.1347      0.028     -4.776      0.000      -0.190      -0.079\n",
      "fr            -0.0094      0.011     -0.824      0.410      -0.032       0.013\n",
      "ie            -0.0935      0.010     -9.046      0.000      -0.114      -0.073\n",
      "it            -0.0360      0.041     -0.883      0.377      -0.116       0.044\n",
      "lu             0.0187      0.043      0.433      0.665      -0.066       0.103\n",
      "nl             0.0308      0.012      2.680      0.007       0.008       0.053\n",
      "at             0.0904      0.010      9.500      0.000       0.072       0.109\n",
      "pt            -0.0085      0.030     -0.283      0.777      -0.068       0.051\n",
      "fi            -0.0771      0.047     -1.644      0.100      -0.169       0.015\n",
      "se            -0.0787      0.015     -5.392      0.000      -0.107      -0.050\n",
      "uk             0.0024      0.006      0.406      0.685      -0.009       0.014\n",
      "no             0.0093      0.013      0.710      0.478      -0.016       0.035\n",
      "is                  0          0        nan        nan           0           0\n",
      "ch             0.0869      0.033      2.639      0.008       0.022       0.151\n",
      "==============================================================================\n",
      "Omnibus:                        1.562   Durbin-Watson:                   0.733\n",
      "Prob(Omnibus):                  0.458   Jarque-Bera (JB):                1.276\n",
      "Skew:                          -0.029   Prob(JB):                        0.528\n",
      "Kurtosis:                       3.385   Cond. No.                     1.12e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "[2] The smallest eigenvalue is 3.35e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance of constraints does not have full rank. The number of constraints is 39, but rank is 38\n"
     ]
    }
   ],
   "source": [
    "# Define the independent variables\n",
    "X = data_filtered[non_eu_immigration + first_instruments + years + country]\n",
    "\n",
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "y = data_filtered['lne_p']\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X).fit(cov_type=\"HC3\")\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple 2SLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearmodels.iv import IV2SLS\n",
    "\n",
    "#from statsmodels.api import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lnf_lf1']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "data_filtered = df_immigration[(df_immigration['is'] == 0) & (df_immigration['dman'] == 1)]\n",
    "data_filtered = data_filtered[['lne_p'] + ['lnf_lf1', 'NEU_ls', 'NEU_ep', 'NEU_rr', 'dold'] + first_instruments + eu_immigration+ inst3b + years + country].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the dependent variable column\n",
    "dependent = data_filtered[['lne_p']]\n",
    "\n",
    "#endogenous variables\n",
    "endog = data_filtered[non_eu_immigration]\n",
    "\n",
    "# exogenous variables\n",
    "exog = data_filtered[first_instruments+years] \n",
    "\n",
    "#Build out the instruments matrix. Statsmodels requires this matrix to contain not only all the\n",
    "# instruments but also the variables in exog that will NOT be instrumented\n",
    "#instruments = data_filtered[years + inst3b] #+ country + ['dold'] #WORKING!!!\n",
    "instruments = data_filtered[[\"nowarpr1\", \"nbospr1\", \"nkospr1\"]+years] #+ country + ['dold'] #WORKING!!! #[\"nowarpr1\",\"nbospr1\",\"nkospr1\"]\n",
    "\n",
    "# # # Define the IV regression formula with multiple endogenous variables\n",
    "# formula = ('lne_p ~ 1 + ' + ' + '.join(exog) + ' + ' +\n",
    "#            '[lnf_lf1  ~ ' + ' + '.join(years[3:]) + ' + ' + ' + '.join(country[2:]) +  ' + ' + ' + '.join(inst3b[2:]) + ']') #+ dold\n",
    "\n",
    "#### WORKING\n",
    "# Define the IV regression formula with multiple endogenous variables\n",
    "formula = ('lne_p ~ 1 + ' + ' + '.join(exog) + ' + ' +\n",
    "           '[lnf_lf1  ~ ' + '+ '.join(instruments) +  ']') #+ dold\n",
    "\n",
    "###### THE PROBLEM IS WITH THE COUNTRY\n",
    "# Define the IV regression formula with multiple endogenous variables\n",
    "# formula = ('lne_p ~ 1 + ' + ' + '.join(exog) + ' + ' +\n",
    "#            '[lnf_lf1  ~ ' + '+ '.join(inst3b) + '+' + ' + '.join(years) +  '+' + ' + '.join(country) + ']') #+ dold\n",
    "\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2SLS, BE-LS-RR, entire sample with country and time effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "data_filtered = df_immigration[(df_immigration['is'] == 0) & (df_immigration['dman'] == 1)] # & (df_immigration['dold'] == 0)\n",
    "data_filtered = data_filtered[['lne_p'] + ['lnf_lf1', 'NEU_ls', 'NEU_ep', 'NEU_rr'] + first_instruments + inst3b + years + country].dropna()\n",
    "\n",
    "country_without_is = [i for i in country if i not in [\"is\", 'ch', 'lu', 'gr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the dependent variable column\n",
    "dependent = ['lne_p']\n",
    "\n",
    "#endogenous variables\n",
    "endog = non_eu_immigration_share + ['NEU_ep', 'NEU_ls', 'NEU_rr']\n",
    "\n",
    "# exogenous variables\n",
    "exog = country_without_is+years\n",
    "\n",
    "# instruments\n",
    "instruments = inst3b+country_without_is+years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ". \n",
      ".     ivregress 2sls lne_p (lnf_lf1 NEU_ep NEU_ls NEU_rr = nbosds12 noward12 nk\n",
      "> osds12 nbos_ep nowar_ep nkos_ep nbos_ls nowar_ls nkos_ls nbos_rr nowar_rr nko\n",
      "> s_rr be dk de91 de_91 es fr ie it nl at pt fi se uk no lneu_lf1 d84 d85 d86 d\n",
      "> 87 d88 d89 d90 d91 d92 d93 d94 d95 d96 d97 d98 d99) be dk de91 de_91 es fr ie\n",
      ">  it nl at pt fi se uk no lneu_lf1 d84 d85 d86 d87 d88 d89 d90 d91 d92 d93 d94\n",
      ">  d95 d96 d97 d98 d99, vce(robust)\n",
      "\n",
      "Instrumental variables 2SLS regression            Number of obs   =        334\n",
      "                                                  Wald chi2(36)   =     861.61\n",
      "                                                  Prob > chi2     =     0.0000\n",
      "                                                  R-squared       =     0.6609\n",
      "                                                  Root MSE        =     .03483\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "       lne_p | Coefficient  std. err.      z    P>|z|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "     lnf_lf1 |  -.0551745   .0296684    -1.86   0.063    -.1133235    .0029746\n",
      "      NEU_ep |  -.0878171   .0300303    -2.92   0.003    -.1466754   -.0289588\n",
      "      NEU_ls |   .0242935   .0177391     1.37   0.171    -.0104745    .0590614\n",
      "      NEU_rr |   .0061683   .0111585     0.55   0.580     -.015702    .0280386\n",
      "          be |  -.3465693   .0818582    -4.23   0.000    -.5070085   -.1861302\n",
      "          dk |   .4310135   .1407453     3.06   0.002     .1551579    .7068692\n",
      "        de91 |    .168758   .1078106     1.57   0.118    -.0425469    .3800628\n",
      "       de_91 |   .1651987   .1040853     1.59   0.112    -.0388048    .3692022\n",
      "          es |    .281873   .2121953     1.33   0.184    -.1340222    .6977683\n",
      "          fr |  -.2040254   .0620267    -3.29   0.001    -.3255955   -.0824553\n",
      "          ie |   .3730478   .1896601     1.97   0.049     .0013209    .7447747\n",
      "          it |  -.4460511   .1971031    -2.26   0.024    -.8323661   -.0597361\n",
      "          nl |   .4611215   .1836674     2.51   0.012     .1011399     .821103\n",
      "          at |   .3953455   .1676481     2.36   0.018     .0667613    .7239298\n",
      "          pt |   .4524672   .1543946     2.93   0.003     .1498593    .7550752\n",
      "          fi |   .1037927   .1110707     0.93   0.350    -.1139018    .3214873\n",
      "          se |   .3305461   .1842202     1.79   0.073    -.0305188     .691611\n",
      "          uk |   .6661927   .2383387     2.80   0.005     .1990574    1.133328\n",
      "          no |    .549452   .1987697     2.76   0.006     .1598705    .9390334\n",
      "    lneu_lf1 |   .0596642   .0233287     2.56   0.011     .0139407    .1053876\n",
      "         d84 |  -.0051151   .0129252    -0.40   0.692    -.0304481    .0202179\n",
      "         d85 |  -.0189765   .0131505    -1.44   0.149    -.0447509     .006798\n",
      "         d86 |  -.0048992   .0133685    -0.37   0.714    -.0311009    .0213025\n",
      "         d87 |  -.0122978   .0138683    -0.89   0.375    -.0394791    .0148835\n",
      "         d88 |  -.0058754   .0139182    -0.42   0.673    -.0331547    .0214038\n",
      "         d89 |   .0072076   .0132405     0.54   0.586    -.0187432    .0331585\n",
      "         d90 |   .0147326   .0133565     1.10   0.270    -.0114456    .0409109\n",
      "         d91 |   .0066402   .0129661     0.51   0.609     -.018773    .0320533\n",
      "         d92 |  -.0072293   .0131109    -0.55   0.581    -.0329262    .0184676\n",
      "         d93 |  -.0175322   .0144685    -1.21   0.226    -.0458899    .0108255\n",
      "         d94 |  -.0226429   .0138237    -1.64   0.101    -.0497369     .004451\n",
      "         d95 |  -.0289395   .0137796    -2.10   0.036     -.055947   -.0019321\n",
      "         d96 |  -.0166403   .0129841    -1.28   0.200    -.0420887    .0088081\n",
      "         d97 |  -.0134258   .0129693    -1.04   0.301    -.0388452    .0119936\n",
      "         d98 |   .0016116   .0135797     0.12   0.906    -.0250041    .0282273\n",
      "         d99 |   .0168458   .0141194     1.19   0.233    -.0108278    .0445194\n",
      "       _cons |  -.4073055   .1644687    -2.48   0.013    -.7296582   -.0849527\n",
      "------------------------------------------------------------------------------\n",
      "Instrumented: lnf_lf1 NEU_ep NEU_ls NEU_rr\n",
      " Instruments: be dk de91 de_91 es fr ie it nl at pt fi se uk no lneu_lf1 d84\n",
      "              d85 d86 d87 d88 d89 d90 d91 d92 d93 d94 d95 d96 d97 d98 d99\n",
      "              nbosds12 noward12 nkosds12 nbos_ep nowar_ep nkos_ep nbos_ls\n",
      "              nowar_ls nkos_ls nbos_rr nowar_rr nkos_rr\n",
      "\n",
      ". \n"
     ]
    }
   ],
   "source": [
    "stata.pdataframe_to_data(data_filtered, force=True)\n",
    "\n",
    "stata.run(f'''\n",
    "    ivregress 2sls {''.join(dependent)} ({' '.join(endog)} = {' '.join(instruments)}) {' '.join(exog)}, vce(robust)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2SLS, BE-LS-RR, all men with country and time effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stata regression:\n",
    "\n",
    "ivregress 2sls lne_p (lnf_lf1 NEU_ep NEU_ls NEU_rr = lneu_lf1 nbosds12 noward12 nkosds12 nbos_ep nowar_ep nkos_ep nbos_ls nowar_ls nkos_ls nbos_rr nowar_rr nkos_rr d84 d85 d86 d87 d88 d89 d90 d91 d92 d93 d94 d95 d96 d97 d98 d99 be dk de91 de_91 gr es fr ie it lu nl at pt fi se uk no is ch) lneu_lf1 d84 d85 d86 d87 d88 d89 d90 d91 d92 d93 d94 d95 d96 d97 d98 d99 be dk de91 de_91 gr es fr ie it lu nl at pt fi se uk no is ch, vce(robust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "data_filtered = df_immigration[(df_immigration['is'] == 0) & (df_immigration['dman'] == 1) & (df_immigration['dold'] == 0)]\n",
    "data_filtered = data_filtered[['lne_p'] + ['lnf_lf1', 'NEU_ls', 'NEU_ep', 'NEU_rr'] + first_instruments + inst3b + years + country].dropna()\n",
    "\n",
    "country_without_is = [i for i in country if i not in [\"is\", 'ch', 'lu', 'gr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the dependent variable column\n",
    "dependent = ['lne_p']\n",
    "\n",
    "#endogenous variables\n",
    "endog = non_eu_immigration_share + ['NEU_ep', 'NEU_ls', 'NEU_rr']\n",
    "\n",
    "# exogenous variables\n",
    "exog = country_without_is+years\n",
    "\n",
    "# instruments\n",
    "instruments = inst3b+country_without_is+years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ". \n",
      ".     ivregress 2sls lne_p (lnf_lf1 NEU_ep NEU_ls NEU_rr = nbosds12 noward12 nk\n",
      "> osds12 nbos_ep nowar_ep nkos_ep nbos_ls nowar_ls nkos_ls nbos_rr nowar_rr nko\n",
      "> s_rr be dk de91 de_91 es fr ie it nl at pt fi se uk no lneu_lf1 d84 d85 d86 d\n",
      "> 87 d88 d89 d90 d91 d92 d93 d94 d95 d96 d97 d98 d99) be dk de91 de_91 es fr ie\n",
      ">  it nl at pt fi se uk no lneu_lf1 d84 d85 d86 d87 d88 d89 d90 d91 d92 d93 d94\n",
      ">  d95 d96 d97 d98 d99, vce(robust)\n",
      "\n",
      "Instrumental variables 2SLS regression            Number of obs   =        167\n",
      "                                                  Wald chi2(36)   =    2321.53\n",
      "                                                  Prob > chi2     =     0.0000\n",
      "                                                  R-squared       =     0.8473\n",
      "                                                  Root MSE        =     .02686\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "       lne_p | Coefficient  std. err.      z    P>|z|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "     lnf_lf1 |   .0527404   1.310377     0.04   0.968     -2.51555    2.621031\n",
      "      NEU_ep |  -.0541044   .0279434    -1.94   0.053    -.1088724    .0006635\n",
      "      NEU_ls |   .0018338   .0360223     0.05   0.959    -.0687686    .0724361\n",
      "      NEU_rr |   .0237871   .3696848     0.06   0.949    -.7007818    .7483559\n",
      "          be |  -.2105472   .0746004    -2.82   0.005    -.3567613   -.0643332\n",
      "          dk |   .3493124   .2034743     1.72   0.086    -.0494899    .7481148\n",
      "        de91 |   .0737378   .1183993     0.62   0.533    -.1583206    .3057962\n",
      "       de_91 |   .0385842   .1158922     0.33   0.739    -.1885603    .2657288\n",
      "          es |   .0093709    .197727     0.05   0.962    -.3781668    .3969087\n",
      "          fr |  -.1730079   .0953534    -1.81   0.070    -.3598971    .0138813\n",
      "          ie |    .230155    .242456     0.95   0.342    -.2450501    .7053601\n",
      "          it |  -.3465334   .3297399    -1.05   0.293    -.9928118     .299745\n",
      "          nl |   .2878523   .1731349     1.66   0.096    -.0514858    .6271904\n",
      "          at |   .2763945   .1832039     1.51   0.131    -.0826785    .6354676\n",
      "          pt |    .326307   .1557048     2.10   0.036     .0211312    .6314828\n",
      "          fi |   .0732892   .1189816     0.62   0.538    -.1599103    .3064888\n",
      "          se |   .0712465   .1680118     0.42   0.672    -.2580505    .4005435\n",
      "          uk |   .5446547   .2532506     2.15   0.032     .0482926    1.041017\n",
      "          no |   .3285825   .1919685     1.71   0.087    -.0476689    .7048339\n",
      "    lneu_lf1 |    .057572   .0235014     2.45   0.014     .0115101     .103634\n",
      "         d84 |  -.0022686   .0210003    -0.11   0.914    -.0434284    .0388913\n",
      "         d85 |   -.009394    .021285    -0.44   0.659    -.0511118    .0323238\n",
      "         d86 |   .0075291   .0218404     0.34   0.730    -.0352773    .0503355\n",
      "         d87 |   .0026317   .0201305     0.13   0.896    -.0368233    .0420867\n",
      "         d88 |   .0065083   .0204511     0.32   0.750    -.0335752    .0465917\n",
      "         d89 |   .0201338   .0201768     1.00   0.318    -.0194121    .0596797\n",
      "         d90 |   .0291639   .0202271     1.44   0.149    -.0104805    .0688083\n",
      "         d91 |   .0166637   .0208739     0.80   0.425    -.0242484    .0575758\n",
      "         d92 |   -.001828   .0200548    -0.09   0.927    -.0411346    .0374787\n",
      "         d93 |  -.0198173   .0204311    -0.97   0.332    -.0598614    .0202269\n",
      "         d94 |   -.024338   .0187109    -1.30   0.193    -.0610107    .0123346\n",
      "         d95 |  -.0244911   .0194952    -1.26   0.209    -.0627009    .0137187\n",
      "         d96 |  -.0149628   .0185741    -0.81   0.420    -.0513674    .0214418\n",
      "         d97 |   -.008813   .0190955    -0.46   0.644    -.0462395    .0286135\n",
      "         d98 |   .0078643   .0195426     0.40   0.687    -.0304385    .0461671\n",
      "         d99 |   .0267876   .0197561     1.36   0.175    -.0119337    .0655088\n",
      "       _cons |  -.2361031   .1695457    -1.39   0.164    -.5684065    .0962002\n",
      "------------------------------------------------------------------------------\n",
      "Instrumented: lnf_lf1 NEU_ep NEU_ls NEU_rr\n",
      " Instruments: be dk de91 de_91 es fr ie it nl at pt fi se uk no lneu_lf1 d84\n",
      "              d85 d86 d87 d88 d89 d90 d91 d92 d93 d94 d95 d96 d97 d98 d99\n",
      "              nbosds12 noward12 nkosds12 nbos_ep nowar_ep nkos_ep nbos_ls\n",
      "              nowar_ls nkos_ls nbos_rr nowar_rr nkos_rr\n",
      "\n",
      ". \n"
     ]
    }
   ],
   "source": [
    "stata.pdataframe_to_data(data_filtered, force=True)\n",
    "\n",
    "stata.run(f'''\n",
    "    ivregress 2sls {''.join(dependent)} ({' '.join(endog)} = {' '.join(instruments)}) {' '.join(exog)}, vce(robust)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoubleML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variable setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Without interactions with institutions\n",
    "#######################\n",
    "\n",
    "\n",
    "#Build the dependent variable column\n",
    "dependent = ['lne_p']\n",
    "\n",
    "#endogenous variables\n",
    "endog = non_eu_immigration_share #+ ['NEU_ep', 'NEU_ls', 'NEU_rr']\n",
    "\n",
    "# exogenous variables\n",
    "exog = country+years+ctrends+population_variables+macroeconomic_variables #country+years+ctrends+ #+country_without_is #+ ['dold']\n",
    "\n",
    "# instruments\n",
    "instruments = first_instruments #inst3b \n",
    "\n",
    "year_index_variable = ['year_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# With interactions with institutions\n",
    "#######################\n",
    "\n",
    "#Build the dependent variable column\n",
    "dependent = ['lne_p']\n",
    "\n",
    "#endogenous variables\n",
    "endog = non_eu_immigration_share + ['NEU_ep', 'NEU_ls', 'NEU_rr']\n",
    "\n",
    "# exogenous variables\n",
    "exog = years+ctrends+country #+country_without_is\n",
    "\n",
    "# instruments\n",
    "instruments = inst3b #+years+country #+country_without_is\n",
    "\n",
    "year_index_variable = ['year_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([\"country\"]+year_index_variable+dependent+endog+exog+instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "data_filtered = df_immigration[(df_immigration['is'] == 0) & (df_immigration['dman'] == 1) & (df_immigration['dold'] == 0)] # & (df_immigration['dold'] == 0)\n",
    "#data_filtered = data_filtered[['lne_p'] + ['lnf_lf1', 'NEU_ls', 'NEU_ep', 'NEU_rr'] + first_instruments + inst3b + years + country + ctrends].dropna()\n",
    "data_filtered = data_filtered[[\"country\"]+year_index_variable+dependent+endog+exog+instruments].dropna()\n",
    "country_without_is = [i for i in country if i not in [\"is\", 'ch', 'lu', 'gr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 74)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered['country'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year_datetime</th>\n",
       "      <th>lne_p</th>\n",
       "      <th>lnf_lf1</th>\n",
       "      <th>tpop1</th>\n",
       "      <th>tlf</th>\n",
       "      <th>tpop</th>\n",
       "      <th>allpop</th>\n",
       "      <th>natpop</th>\n",
       "      <th>natemp</th>\n",
       "      <th>...</th>\n",
       "      <th>sfeupop1</th>\n",
       "      <th>seulf2</th>\n",
       "      <th>gdp_gr</th>\n",
       "      <th>urate</th>\n",
       "      <th>lag_gdp</th>\n",
       "      <th>schengen</th>\n",
       "      <th>p96schen</th>\n",
       "      <th>nbospr1</th>\n",
       "      <th>nowarpr1</th>\n",
       "      <th>nkospr1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT</td>\n",
       "      <td>1996</td>\n",
       "      <td>-0.016718</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>4.993652</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>-9.421753</td>\n",
       "      <td>-14.280396</td>\n",
       "      <td>-28.657471</td>\n",
       "      <td>...</td>\n",
       "      <td>1120.625000</td>\n",
       "      <td>-4759.929688</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT</td>\n",
       "      <td>1997</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>0.043246</td>\n",
       "      <td>8.721680</td>\n",
       "      <td>2.349365</td>\n",
       "      <td>8.721680</td>\n",
       "      <td>-19.124756</td>\n",
       "      <td>-9.133057</td>\n",
       "      <td>2.284241</td>\n",
       "      <td>...</td>\n",
       "      <td>13332.531250</td>\n",
       "      <td>5741.469727</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>-0.051436</td>\n",
       "      <td>10.360352</td>\n",
       "      <td>35.791748</td>\n",
       "      <td>10.360352</td>\n",
       "      <td>-16.282715</td>\n",
       "      <td>-20.574951</td>\n",
       "      <td>-8.039062</td>\n",
       "      <td>...</td>\n",
       "      <td>-4206.468750</td>\n",
       "      <td>3824.250000</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>-0.026346</td>\n",
       "      <td>2.160156</td>\n",
       "      <td>8.629395</td>\n",
       "      <td>2.160156</td>\n",
       "      <td>-19.733154</td>\n",
       "      <td>-19.349365</td>\n",
       "      <td>-10.157104</td>\n",
       "      <td>...</td>\n",
       "      <td>-7195.562500</td>\n",
       "      <td>-4226.050781</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.439</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BE</td>\n",
       "      <td>1984</td>\n",
       "      <td>-0.013648</td>\n",
       "      <td>-0.160821</td>\n",
       "      <td>68.652832</td>\n",
       "      <td>70.500488</td>\n",
       "      <td>68.652832</td>\n",
       "      <td>56.497192</td>\n",
       "      <td>62.233643</td>\n",
       "      <td>37.014771</td>\n",
       "      <td>...</td>\n",
       "      <td>-16562.484375</td>\n",
       "      <td>-1432.281250</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>UK</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.016763</td>\n",
       "      <td>0.021232</td>\n",
       "      <td>104.734375</td>\n",
       "      <td>21.792969</td>\n",
       "      <td>104.734375</td>\n",
       "      <td>-9.017578</td>\n",
       "      <td>-17.560547</td>\n",
       "      <td>100.347656</td>\n",
       "      <td>...</td>\n",
       "      <td>8403.937500</td>\n",
       "      <td>-24977.437500</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.889</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>UK</td>\n",
       "      <td>1996</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>85.216797</td>\n",
       "      <td>73.320312</td>\n",
       "      <td>85.216797</td>\n",
       "      <td>-15.607422</td>\n",
       "      <td>-12.097656</td>\n",
       "      <td>-14.133789</td>\n",
       "      <td>...</td>\n",
       "      <td>-6008.625000</td>\n",
       "      <td>-16621.562500</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.611</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003125</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>UK</td>\n",
       "      <td>1997</td>\n",
       "      <td>0.021285</td>\n",
       "      <td>0.065624</td>\n",
       "      <td>3.394531</td>\n",
       "      <td>1.484375</td>\n",
       "      <td>3.394531</td>\n",
       "      <td>-84.915039</td>\n",
       "      <td>-105.952148</td>\n",
       "      <td>58.487305</td>\n",
       "      <td>...</td>\n",
       "      <td>47669.187500</td>\n",
       "      <td>6500.125000</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-1.427</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003125</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>UK</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.078779</td>\n",
       "      <td>37.082031</td>\n",
       "      <td>40.859375</td>\n",
       "      <td>37.082031</td>\n",
       "      <td>-59.432617</td>\n",
       "      <td>-95.692383</td>\n",
       "      <td>6.762695</td>\n",
       "      <td>...</td>\n",
       "      <td>81151.437500</td>\n",
       "      <td>30559.437500</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.563</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.1625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>UK</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.053490</td>\n",
       "      <td>345.720703</td>\n",
       "      <td>394.425781</td>\n",
       "      <td>345.720703</td>\n",
       "      <td>62.501953</td>\n",
       "      <td>31.634766</td>\n",
       "      <td>33.617188</td>\n",
       "      <td>...</td>\n",
       "      <td>1105.000000</td>\n",
       "      <td>-11580.625000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.1625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  year_datetime     lne_p   lnf_lf1       tpop1         tlf  \\\n",
       "0        AT           1996 -0.016718  0.000567   25.250000    4.993652   \n",
       "1        AT           1997  0.010442  0.043246    8.721680    2.349365   \n",
       "2        AT           1998  0.010113 -0.051436   10.360352   35.791748   \n",
       "3        AT           1999  0.007034 -0.026346    2.160156    8.629395   \n",
       "4        BE           1984 -0.013648 -0.160821   68.652832   70.500488   \n",
       "..      ...            ...       ...       ...         ...         ...   \n",
       "177      UK           1995  0.016763  0.021232  104.734375   21.792969   \n",
       "178      UK           1996 -0.000598  0.005102   85.216797   73.320312   \n",
       "179      UK           1997  0.021285  0.065624    3.394531    1.484375   \n",
       "180      UK           1998  0.012698  0.078779   37.082031   40.859375   \n",
       "181      UK           1999  0.000936 -0.053490  345.720703  394.425781   \n",
       "\n",
       "           tpop     allpop      natpop      natemp  ...      sfeupop1  \\\n",
       "0     25.250000  -9.421753  -14.280396  -28.657471  ...   1120.625000   \n",
       "1      8.721680 -19.124756   -9.133057    2.284241  ...  13332.531250   \n",
       "2     10.360352 -16.282715  -20.574951   -8.039062  ...  -4206.468750   \n",
       "3      2.160156 -19.733154  -19.349365  -10.157104  ...  -7195.562500   \n",
       "4     68.652832  56.497192   62.233643   37.014771  ... -16562.484375   \n",
       "..          ...        ...         ...         ...  ...           ...   \n",
       "177  104.734375  -9.017578  -17.560547  100.347656  ...   8403.937500   \n",
       "178   85.216797 -15.607422  -12.097656  -14.133789  ...  -6008.625000   \n",
       "179    3.394531 -84.915039 -105.952148   58.487305  ...  47669.187500   \n",
       "180   37.082031 -59.432617  -95.692383    6.762695  ...  81151.437500   \n",
       "181  345.720703  62.501953   31.634766   33.617188  ...   1105.000000   \n",
       "\n",
       "           seulf2  gdp_gr  urate  lag_gdp  schengen  p96schen   nbospr1  \\\n",
       "0    -4759.929688  -0.008  0.346    0.003       0.0       1.0  0.000000   \n",
       "1     5741.469727   0.017  0.051   -0.008       0.0       0.0  0.000000   \n",
       "2     3824.250000  -0.008  0.055    0.017       0.0       0.0  0.000000   \n",
       "3    -4226.050781   0.015 -0.439   -0.008       0.0       0.0  0.000000   \n",
       "4    -1432.281250  -0.008  0.062    0.024       0.0       0.0  0.000000   \n",
       "..            ...     ...    ...      ...       ...       ...       ...   \n",
       "177 -24977.437500  -0.002 -0.889   -0.016       0.0       0.0  1.003125   \n",
       "178 -16621.562500   0.009 -0.611   -0.002       0.0       0.0  0.000000   \n",
       "179   6500.125000  -0.009 -1.427    0.009       0.0       0.0  0.000000   \n",
       "180  30559.437500  -0.004 -0.563   -0.009       0.0       0.0  0.000000   \n",
       "181 -11580.625000   0.008  0.123   -0.004       0.0       0.0  0.000000   \n",
       "\n",
       "     nowarpr1  nkospr1  \n",
       "0    0.262500   0.0000  \n",
       "1    0.262500   0.0000  \n",
       "2    0.000000   0.4125  \n",
       "3    0.000000   0.4125  \n",
       "4    0.000000   0.0000  \n",
       "..        ...      ...  \n",
       "177  0.000000   0.0000  \n",
       "178  1.003125   0.0000  \n",
       "179  1.003125   0.0000  \n",
       "180  0.000000   1.1625  \n",
       "181  0.000000   1.1625  \n",
       "\n",
       "[182 rows x 36 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Define the columns to which you want to apply the diff() operation\n",
    "# columns_to_diff = dependent + population_variables + macroeconomic_variables + non_eu_immigration_share  # replace with your actual column names\n",
    "\n",
    "# # Set the index for the DataFrame\n",
    "# data_filtered.set_index(['country', year_index_variable[0]], inplace=True)\n",
    "\n",
    "# # Apply the diff() operation to the selected columns\n",
    "# df_diff = data_filtered[columns_to_diff].groupby(level='country').diff()\n",
    "\n",
    "# # Combine the diffed columns back with the original DataFrame\n",
    "# df_with_diff = data_filtered.copy()  # make a copy of the original DataFrame\n",
    "# df_with_diff[columns_to_diff] = df_diff  # update the selected columns with their diffed values\n",
    "\n",
    "# # Reset the index\n",
    "# df_with_diff = df_with_diff.dropna().reset_index()\n",
    "\n",
    "# # Optionally, drop rows with NaN values generated by the diff() operation\n",
    "# #df_with_diff.dropna(inplace=True)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# df_with_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from empirical_analysis.run_models import CausalInferenceModels\n",
    "models = CausalInferenceModels(\n",
    "    df=data_filtered, #df_with_diff,\n",
    "    y_column=dependent[0], \n",
    "    d_columns=endog,\n",
    "    x_columns=exog,\n",
    "    z_columns=instruments, \n",
    "    unit_column='country', \n",
    "    time_column='Time',\n",
    "    desired_alpha=0,\n",
    "    n=data_filtered['country'].nunique()\n",
    "    )\n",
    "\n",
    "models.run_hyperparameter_tuning(\n",
    "    reading_tuned_hp=True,\n",
    "    simulation_or_empirical=\"empirical\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dml_data = dml.DoubleMLClusterData(data_filtered, y_col=dependent[0], x_cols=exog, d_cols=endog, z_cols=instruments, cluster_cols='country') #df_with_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Coefficient': 0.0293,\n",
       " 'Bias': 0.0293,\n",
       " 'Standard Error': 0.0253,\n",
       " 't-Statistic': 1.1566465046374204,\n",
       " 'p-Value': 0.24741681404195315,\n",
       " '95% CI Lower': -0.0203,\n",
       " '95% CI Upper': 0.0788,\n",
       " 'model_name': 'DML: Random Forests',\n",
       " 'size_panel': 17}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_results = models.dml_random_forest(obj_dml_data)\n",
    "random_forest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = {\"lnf_lf1\":0.0614826158,\"NEU_ep\":0.000071612,\"NEU_ls\":0.0068792405,\"NEU_rr\":-0.003085261}\n",
    "std_errors = {\"lnf_lf1\":0.020040569,\"NEU_ep\":0.0031014226,\"NEU_ls\":0.0027028855,\"NEU_rr\":0.0022495549}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endogenous</th>\n",
       "      <th>coef</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lnf_lf1</td>\n",
       "      <td>0.061483</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>DML random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEU_ep</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>DML random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEU_ls</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>DML random forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEU_rr</td>\n",
       "      <td>-0.003085</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>DML random forest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  endogenous      coef   std_dev              model\n",
       "0    lnf_lf1  0.061483  0.020041  DML random forest\n",
       "1     NEU_ep  0.000072  0.003101  DML random forest\n",
       "2     NEU_ls  0.006879  0.002703  DML random forest\n",
       "3     NEU_rr -0.003085  0.002250  DML random forest"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given dictionaries\n",
    "coefs = {\n",
    "    \"lnf_lf1\": 0.0614826158,\n",
    "    \"NEU_ep\": 0.000071612,\n",
    "    \"NEU_ls\": 0.0068792405,\n",
    "    \"NEU_rr\": -0.003085261\n",
    "}\n",
    "\n",
    "std_dev = {\n",
    "    \"lnf_lf1\": 0.020040569,\n",
    "    \"NEU_ep\": 0.0031014226,\n",
    "    \"NEU_ls\": 0.0027028855,\n",
    "    \"NEU_rr\": 0.0022495549\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_tst = pd.DataFrame({\n",
    "    'endogenous': list(coefs.keys()),\n",
    "    'coef': list(coefs.values()),\n",
    "    'std_dev': list(std_dev.values()),\n",
    "    'model': \"DML random forest\"\n",
    "})\n",
    "\n",
    "df_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Coefficient': 0.0406,\n",
       " 'Bias': 0.0406,\n",
       " 'Standard Error': 0.0247,\n",
       " 't-Statistic': 1.6423928258610894,\n",
       " 'p-Value': 0.10050862074667502,\n",
       " '95% CI Lower': -0.0078,\n",
       " '95% CI Upper': 0.089,\n",
       " 'model_name': 'DML: XGBoost',\n",
       " 'size_panel': 17}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_results = models.dml_xgboost(obj_dml_data)\n",
    "xgboost_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Outros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   endogenous      coef   std_dev            model\n",
      "0     lnf_lf1  0.061483  0.020041    random forest\n",
      "1      NEU_ep  0.000072  0.003101    random forest\n",
      "2      NEU_ls  0.006879  0.002703    random forest\n",
      "3      NEU_rr -0.003085  0.002250    random forest\n",
      "4     lnf_lf1  0.061483  0.020041         boosting\n",
      "5      NEU_ep  0.000072  0.003101         boosting\n",
      "6      NEU_ls  0.006879  0.002703         boosting\n",
      "7      NEU_rr -0.003085  0.002250         boosting\n",
      "8     lnf_lf1  0.061483  0.020041  neural networks\n",
      "9      NEU_ep  0.000072  0.003101  neural networks\n",
      "10     NEU_ls  0.006879  0.002703  neural networks\n",
      "11     NEU_rr -0.003085  0.002250  neural networks\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Given dictionaries\n",
    "coefs = {\n",
    "    \"lnf_lf1\": 0.0614826158,\n",
    "    \"NEU_ep\": 0.000071612,\n",
    "    \"NEU_ls\": 0.0068792405,\n",
    "    \"NEU_rr\": -0.003085261\n",
    "}\n",
    "\n",
    "std_dev = {\n",
    "    \"lnf_lf1\": 0.020040569,\n",
    "    \"NEU_ep\": 0.0031014226,\n",
    "    \"NEU_ls\": 0.0027028855,\n",
    "    \"NEU_rr\": 0.0022495549\n",
    "}\n",
    "\n",
    "# Function to create a DataFrame from given dictionaries and model name\n",
    "def create_df(coefs, std_dev, model_name):\n",
    "    return pd.DataFrame({\n",
    "        'endogenous': list(coefs.keys()),\n",
    "        'coef': list(coefs.values()),\n",
    "        'std_dev': list(std_dev.values()),\n",
    "        'model': model_name\n",
    "    })\n",
    "\n",
    "# Create DataFrames for each model\n",
    "df_random_forest = create_df(coefs, std_dev, 'random forest')\n",
    "df_boosting = create_df(coefs, std_dev, 'boosting')\n",
    "df_neural_networks = create_df(coefs, std_dev, 'neural networks')\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df_combined = pd.concat([df_random_forest, df_boosting, df_neural_networks], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"lnf_lf1\":0.020040569,\"NEU_ep\":0.0031014226,\"NEU_ls\":0.0027028855,\"NEU_rr\":0.0022495549}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.actual_fitted_model.summary.iloc[:, 1].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data from the table\n",
    "models = [\"DML: LASSO\", \"DML: Random Forests\", \"DML: Boosting\", \"Original Estimates\"]\n",
    "panel_a_coeffs = [0.0263, 0.0564, 0.0423, -0.042]\n",
    "panel_a_errors = [0.0538, 0.0278, 0.0220, 0.031]\n",
    "panel_b_coeffs = [0.0525, 0.0723, 0.0975, -0.102]\n",
    "panel_b_errors = [0.0283, 0.0235, 0.0480, 0.044]\n",
    "\n",
    "# Plot Panel A\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(models, panel_a_coeffs, yerr=panel_a_errors, fmt='o', capsize=5, capthick=2, markeredgewidth=2, label='Coefficient ± SE')\n",
    "plt.axhline(0, color='grey', linewidth=0.8)\n",
    "#plt.title('Panel A: Without interactions with institutions', fontsize=14)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Coefficient', fontsize=12)\n",
    "plt.xticks(ticks=range(len(models)), labels=models, rotation=0, fontsize=10, ha='center', position=(0, -0.02))\n",
    "plt.ylim(-0.1, 0.15)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Plot Panel B\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(models, panel_b_coeffs, yerr=panel_b_errors, fmt='o', capsize=5, capthick=2, markeredgewidth=2, label='Coefficient ± SE')\n",
    "plt.axhline(0, color='grey', linewidth=0.8)\n",
    "#plt.title('Panel B: With interactions with institutions', fontsize=14)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Coefficient', fontsize=12)\n",
    "plt.xticks(ticks=range(len(models)), labels=models, rotation=0, fontsize=10, ha='center', position=(0, -0.02))\n",
    "plt.ylim(-0.15, 0.15)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lnf_lf1</th>\n",
       "      <td>0.085479</td>\n",
       "      <td>0.067825</td>\n",
       "      <td>1.26029</td>\n",
       "      <td>0.207565</td>\n",
       "      <td>-0.047455</td>\n",
       "      <td>0.218412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef   std err        t     P>|t|     2.5 %    97.5 %\n",
       "lnf_lf1  0.085479  0.067825  1.26029  0.207565 -0.047455  0.218412"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# RANDOM FOREST with exog\n",
    "#####################\n",
    "obj_dml_data = dml.DoubleMLData(data_filtered, y_col=dependent[0], x_cols=exog, d_cols=endog, z_cols=instruments) #\n",
    "\n",
    "learner = RandomForestRegressor(n_estimators=100, max_features=20, max_depth=15, min_samples_leaf=2)\n",
    "ml_l = clone(learner)\n",
    "ml_m = clone(learner)\n",
    "ml_r = clone(learner)\n",
    "\n",
    "dml_pliv_obj_rf = dml.DoubleMLPLIV(obj_dml_data, ml_l, ml_m, ml_r)\n",
    "\n",
    "# Define the parameter grids for hyperparameter tuning\n",
    "par_grids_rf = {'ml_l': {'n_estimators': [50, 100, 200],\n",
    "                      'max_features': [5, 10, 15, 20],\n",
    "                      'max_depth': [10, 15, 20, 25],\n",
    "                      'min_samples_leaf': [1, 2, 4]},\n",
    "             'ml_m': {'n_estimators': [50, 100, 200],\n",
    "                      'max_features': [5, 10, 15, 20],\n",
    "                      'max_depth': [10, 15, 20, 25],\n",
    "                      'min_samples_leaf': [1, 2, 4]},\n",
    "             'ml_r': {'n_estimators': [50, 100, 200],\n",
    "                      'max_features': [5, 10, 15, 20],\n",
    "                      'max_depth': [10, 15, 20, 25],\n",
    "                      'min_samples_leaf': [1, 2, 4]}}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "dml_pliv_obj_rf.tune(par_grids_rf, search_mode='grid_search')\n",
    "\n",
    "dml_pliv_obj_rf.fit().summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lnf_lf1</th>\n",
       "      <td>-0.0298</td>\n",
       "      <td>0.081927</td>\n",
       "      <td>-0.363736</td>\n",
       "      <td>0.716055</td>\n",
       "      <td>-0.190375</td>\n",
       "      <td>0.130775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef   std err         t     P>|t|     2.5 %    97.5 %\n",
       "lnf_lf1 -0.0298  0.081927 -0.363736  0.716055 -0.190375  0.130775"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dml_pliv_obj_rf.fit().summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# GRADIENT BOOSTING with exog\n",
    "#####################\n",
    "\n",
    "#obj_dml_data = dml.DoubleMLData(data_filtered, y_col=dependent[0], x_cols=exog, d_cols=endog, z_cols=instruments) #x_cols=exog, \n",
    "#obj_dml_data = dml.DoubleMLClusterData(data_filtered, y_col=dependent[0], x_cols=exog, d_cols=endog, z_cols=instruments, cluster_cols='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Endogenous</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>t-Statistic</th>\n",
       "      <th>p-value</th>\n",
       "      <th>95_lower_ci</th>\n",
       "      <th>95_upper_ci</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lnf_lf1</td>\n",
       "      <td>0.097541</td>\n",
       "      <td>0.048023</td>\n",
       "      <td>2.031159</td>\n",
       "      <td>0.042239</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.191664</td>\n",
       "      <td>DML: Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEU_ep</td>\n",
       "      <td>-0.001565</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>-0.343591</td>\n",
       "      <td>0.731154</td>\n",
       "      <td>-0.010492</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>DML: Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEU_ls</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>1.634407</td>\n",
       "      <td>0.102173</td>\n",
       "      <td>-0.001189</td>\n",
       "      <td>0.013129</td>\n",
       "      <td>DML: Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEU_rr</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>-0.198295</td>\n",
       "      <td>0.842814</td>\n",
       "      <td>-0.009131</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>DML: Gradient Boosting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Endogenous  Coefficient  Standard Error  t-Statistic   p-value  95_lower_ci  \\\n",
       "0    lnf_lf1     0.097541        0.048023     2.031159  0.042239     0.003419   \n",
       "1     NEU_ep    -0.001565        0.004555    -0.343591  0.731154    -0.010492   \n",
       "2     NEU_ls     0.005970        0.003653     1.634407  0.102173    -0.001189   \n",
       "3     NEU_rr    -0.000839        0.004231    -0.198295  0.842814    -0.009131   \n",
       "\n",
       "   95_upper_ci                   model  \n",
       "0     0.191664  DML: Gradient Boosting  \n",
       "1     0.007362  DML: Gradient Boosting  \n",
       "2     0.013129  DML: Gradient Boosting  \n",
       "3     0.007453  DML: Gradient Boosting  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boosting_results = models.dml_gbm(obj_dml_data)\n",
    "gradient_boosting_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "learner_boosting = GradientBoostingRegressor(n_estimators=100, max_depth=20, learning_rate=0.01)\n",
    "\n",
    "ml_l_boosting = clone(learner_boosting)\n",
    "ml_m_boosting = clone(learner_boosting)\n",
    "ml_r_boosting = clone(learner_boosting)\n",
    "\n",
    "# For boosting\n",
    "dml_pliv_obj_boosting = dml.DoubleMLPLIV(obj_dml_data, ml_l_boosting, ml_m_boosting, ml_r_boosting)\n",
    "\n",
    "# # Define the parameter grids for hyperparameter tuning\n",
    "# par_grids = {'ml_l': {'n_estimators': [50, 100, 200],\n",
    "#                       'max_depth': [10, 15, 20, 25],\n",
    "#                       'learning_rate': [0.01, 0.05, 0.1]},\n",
    "#              'ml_m': {'n_estimators': [50, 100, 200],\n",
    "#                       'max_depth': [10, 15, 20, 25],\n",
    "#                       'learning_rate': [0.01, 0.05, 0.1]},\n",
    "#              'ml_r': {'n_estimators': [50, 100, 200],\n",
    "#                       'max_depth': [10, 15, 20, 25],\n",
    "#                       'learning_rate': [0.01, 0.05, 0.1]}}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "#dml_pliv_obj_boosting.tune(par_grids, search_mode='grid_search')\n",
    "\n",
    "dml_pliv_obj_boosting.fit().summary  # Fit and show summary for boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lnf_lf1</th>\n",
       "      <td>0.035404</td>\n",
       "      <td>0.022919</td>\n",
       "      <td>1.544731</td>\n",
       "      <td>0.122411</td>\n",
       "      <td>-0.009517</td>\n",
       "      <td>0.080325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef   std err         t     P>|t|     2.5 %    97.5 %\n",
       "lnf_lf1  0.035404  0.022919  1.544731  0.122411 -0.009517  0.080325"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dml_pliv_obj_boosting.fit().summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ml_l': {'lnf_lf1': [[{'learning_rate': 0.05,\n",
       "     'max_depth': 10,\n",
       "     'n_estimators': 100},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}]]},\n",
       " 'ml_r': {'lnf_lf1': [[{'learning_rate': 0.05,\n",
       "     'max_depth': 15,\n",
       "     'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 200}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100}]]},\n",
       " 'ml_m_nbosds12': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 10,\n",
       "     'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200}]]},\n",
       " 'ml_m_noward12': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 20,\n",
       "     'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 200}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200}]]},\n",
       " 'ml_m_nkosds12': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 15,\n",
       "     'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 100}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50}]]},\n",
       " 'ml_m_nbos_ep': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 15,\n",
       "     'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 100}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100}]]},\n",
       " 'ml_m_nowar_ep': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 10,\n",
       "     'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 50}]]},\n",
       " 'ml_m_nkos_ep': {'lnf_lf1': [[{'learning_rate': 0.05,\n",
       "     'max_depth': 10,\n",
       "     'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 100}]]},\n",
       " 'ml_m_nbos_ls': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 25,\n",
       "     'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100}]]},\n",
       " 'ml_m_nowar_ls': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 10,\n",
       "     'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50}]]},\n",
       " 'ml_m_nkos_ls': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 20,\n",
       "     'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 200}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50}]]},\n",
       " 'ml_m_nbos_rr': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 10,\n",
       "     'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 50}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 200}]]},\n",
       " 'ml_m_nowar_rr': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 10,\n",
       "     'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 50}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 50}]]},\n",
       " 'ml_m_nkos_rr': {'lnf_lf1': [[{'learning_rate': 0.01,\n",
       "     'max_depth': 25,\n",
       "     'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50},\n",
       "    {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50}]],\n",
       "  'NEU_ep': [[{'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_ls': [[{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200}]],\n",
       "  'NEU_rr': [[{'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200},\n",
       "    {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200}]]}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dml_pliv_obj_boosting.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lnf_lf1</th>\n",
       "      <td>2.545837</td>\n",
       "      <td>2.440401</td>\n",
       "      <td>1.043204</td>\n",
       "      <td>0.296854</td>\n",
       "      <td>-2.237262</td>\n",
       "      <td>7.328936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU_ep</th>\n",
       "      <td>-0.537765</td>\n",
       "      <td>0.900142</td>\n",
       "      <td>-0.597423</td>\n",
       "      <td>0.550225</td>\n",
       "      <td>-2.302011</td>\n",
       "      <td>1.226481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU_ls</th>\n",
       "      <td>-2.481135</td>\n",
       "      <td>1.610966</td>\n",
       "      <td>-1.540154</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>-5.638570</td>\n",
       "      <td>0.676300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU_rr</th>\n",
       "      <td>-2.622646</td>\n",
       "      <td>2.910936</td>\n",
       "      <td>-0.900963</td>\n",
       "      <td>0.367608</td>\n",
       "      <td>-8.327976</td>\n",
       "      <td>3.082684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef   std err         t     P>|t|     2.5 %    97.5 %\n",
       "lnf_lf1  2.545837  2.440401  1.043204  0.296854 -2.237262  7.328936\n",
       "NEU_ep  -0.537765  0.900142 -0.597423  0.550225 -2.302011  1.226481\n",
       "NEU_ls  -2.481135  1.610966 -1.540154  0.123523 -5.638570  0.676300\n",
       "NEU_rr  -2.622646  2.910936 -0.900963  0.367608 -8.327976  3.082684"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dml_pliv_obj_boosting.fit().summary  # Fit and show summary for boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLPLIV Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: lne_p\n",
      "Treatment variable(s): ['lnf_lf1', 'NEU_ep', 'NEU_ls', 'NEU_rr']\n",
      "Covariates: ['lneu_lf1', 'd84', 'd85', 'd86', 'd87', 'd88', 'd89', 'd90', 'd91', 'd92', 'd93', 'd94', 'd95', 'd96', 'd97', 'd98', 'd99', 'trendbe', 'trendk', 'trende91', 'trend_91', 'trendgr', 'trendes', 'trendfr', 'trendie', 'trendit', 'trendlu', 'trendnl', 'trendat', 'trendpt', 'trendfi', 'trendse', 'trenduk', 'trendno', 'trendis', 'trendch', 'be', 'dk', 'de91', 'de_91', 'gr', 'es', 'fr', 'ie', 'it', 'lu', 'nl', 'at', 'pt', 'fi', 'se', 'uk', 'no', 'is', 'ch']\n",
      "Instrument variable(s): ['nbosds12', 'noward12', 'nkosds12', 'nbos_ep', 'nowar_ep', 'nkos_ep', 'nbos_ls', 'nowar_ls', 'nkos_ls', 'nbos_rr', 'nowar_rr', 'nkos_rr']\n",
      "No. Observations: 167\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "DML algorithm: dml2\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: GradientBoostingRegressor(learning_rate=0.01, max_depth=20)\n",
      "Learner ml_m: GradientBoostingRegressor(learning_rate=0.01, max_depth=20)\n",
      "Learner ml_r: GradientBoostingRegressor(learning_rate=0.01, max_depth=20)\n",
      "Out-of-sample Performance:\n",
      "Learner ml_l RMSE: [[0.02431735 0.02626118 0.02747126 0.02578308]]\n",
      "Learner ml_r RMSE: [[0.00329411 0.00436263 0.00252022 0.00338283]]\n",
      "Learner ml_m_nbosds12 RMSE: [[0.21336425 0.2270018  0.23228001 0.20466058]]\n",
      "Learner ml_m_noward12 RMSE: [[0.18291076 0.20263616 0.20479978 0.19447526]]\n",
      "Learner ml_m_nkosds12 RMSE: [[0.17857768 0.17867245 0.17062665 0.17135729]]\n",
      "Learner ml_m_nbos_ep RMSE: [[0.3522442  0.35355542 0.3603024  0.34650732]]\n",
      "Learner ml_m_nowar_ep RMSE: [[0.35908973 0.37457693 0.34311693 0.36516928]]\n",
      "Learner ml_m_nkos_ep RMSE: [[0.27141747 0.29717904 0.2701049  0.27594933]]\n",
      "Learner ml_m_nbos_ls RMSE: [[0.38646723 0.40231499 0.40847653 0.39808155]]\n",
      "Learner ml_m_nowar_ls RMSE: [[0.38239539 0.37340627 0.41324262 0.38187363]]\n",
      "Learner ml_m_nkos_ls RMSE: [[0.30126526 0.30095503 0.30094884 0.30078821]]\n",
      "Learner ml_m_nbos_rr RMSE: [[0.31567462 0.32524811 0.30705703 0.30790359]]\n",
      "Learner ml_m_nowar_rr RMSE: [[0.35729415 0.34468594 0.34784543 0.32626644]]\n",
      "Learner ml_m_nkos_rr RMSE: [[0.28931994 0.28960235 0.28863986 0.28957404]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "Apply cross-fitting: True\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "             coef   std err         t     P>|t|     2.5 %     97.5 %\n",
      "lnf_lf1  0.610062  3.449123  0.176874  0.859607 -6.150095   7.370219\n",
      "NEU_ep  -1.418554  1.556651 -0.911286  0.362145 -4.469535   1.632426\n",
      "NEU_ls   5.503320  5.200993  1.058129  0.289997 -4.690438  15.697078\n",
      "NEU_rr   0.293698  1.277479  0.229904  0.818166 -2.210115   2.797511\n"
     ]
    }
   ],
   "source": [
    "print(dml_pliv_obj_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lnf_lf1</th>\n",
       "      <td>0.035770</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>3.649333</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.016559</td>\n",
       "      <td>0.054981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU_ep</th>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>1.295915</td>\n",
       "      <td>0.195005</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>0.004360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU_ls</th>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>2.184549</td>\n",
       "      <td>0.028922</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.007954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU_rr</th>\n",
       "      <td>-0.005110</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>-3.487647</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>-0.007982</td>\n",
       "      <td>-0.002238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef   std err         t     P>|t|     2.5 %    97.5 %\n",
       "lnf_lf1  0.035770  0.009802  3.649333  0.000263  0.016559  0.054981\n",
       "NEU_ep   0.001736  0.001339  1.295915  0.195005 -0.000889  0.004360\n",
       "NEU_ls   0.004192  0.001919  2.184549  0.028922  0.000431  0.007954\n",
       "NEU_rr  -0.005110  0.001465 -3.487647  0.000487 -0.007982 -0.002238"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# GRADIENT BOOSTING with exog\n",
    "#####################\n",
    "\n",
    "obj_dml_data = dml.DoubleMLData(data_filtered, y_col=dependent[0], d_cols=endog, z_cols=instruments) #x_cols=exog, \n",
    "\n",
    "learner_boosting = GradientBoostingRegressor(n_estimators=100, max_depth=15, learning_rate=0.01)\n",
    "\n",
    "ml_l_boosting = clone(learner_boosting)\n",
    "ml_m_boosting = clone(learner_boosting)\n",
    "ml_r_boosting = clone(learner_boosting)\n",
    "\n",
    "# For boosting\n",
    "dml_pliv_obj_boosting = dml.DoubleMLPLIV(obj_dml_data, ml_l_boosting, ml_m_boosting, ml_r_boosting)\n",
    "dml_pliv_obj_boosting.fit().summary  # Fit and show summary for boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e-02, tolerance: 8.701e-03\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Endogenous</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>t-Statistic</th>\n",
       "      <th>p-value</th>\n",
       "      <th>95_lower_ci</th>\n",
       "      <th>95_upper_ci</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lnf_lf1</td>\n",
       "      <td>0.052490</td>\n",
       "      <td>0.028284</td>\n",
       "      <td>1.855834</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>-0.002945</td>\n",
       "      <td>0.107925</td>\n",
       "      <td>DML: LASSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEU_ep</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.469258</td>\n",
       "      <td>0.638885</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>DML: LASSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEU_ls</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>2.535701</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>DML: LASSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEU_rr</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>-0.618754</td>\n",
       "      <td>0.536079</td>\n",
       "      <td>-0.008429</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>DML: LASSO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Endogenous  Coefficient  Standard Error  t-Statistic   p-value  95_lower_ci  \\\n",
       "0    lnf_lf1     0.052490        0.028284     1.855834  0.063477    -0.002945   \n",
       "1     NEU_ep     0.001229        0.002618     0.469258  0.638885    -0.003903   \n",
       "2     NEU_ls     0.008573        0.003381     2.535701  0.011222     0.001947   \n",
       "3     NEU_rr    -0.002023        0.003269    -0.618754  0.536079    -0.008429   \n",
       "\n",
       "   95_upper_ci       model  \n",
       "0     0.107925  DML: LASSO  \n",
       "1     0.006360  DML: LASSO  \n",
       "2     0.015200  DML: LASSO  \n",
       "3     0.004384  DML: LASSO  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_results = models.dml_lasso(obj_dml_data)\n",
    "lasso_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lnf_lf1</th>\n",
       "      <td>0.034496</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>9.999224</td>\n",
       "      <td>1.535963e-23</td>\n",
       "      <td>0.027735</td>\n",
       "      <td>0.041258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU_ep</th>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.772169</td>\n",
       "      <td>4.400142e-01</td>\n",
       "      <td>-0.001178</td>\n",
       "      <td>0.002710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU_ls</th>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>3.403344</td>\n",
       "      <td>6.656648e-04</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.006057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEU_rr</th>\n",
       "      <td>-0.003643</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>-5.714943</td>\n",
       "      <td>1.097406e-08</td>\n",
       "      <td>-0.004892</td>\n",
       "      <td>-0.002394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef   std err         t         P>|t|     2.5 %    97.5 %\n",
       "lnf_lf1  0.034496  0.003450  9.999224  1.535963e-23  0.027735  0.041258\n",
       "NEU_ep   0.000766  0.000992  0.772169  4.400142e-01 -0.001178  0.002710\n",
       "NEU_ls   0.003843  0.001129  3.403344  6.656648e-04  0.001630  0.006057\n",
       "NEU_rr  -0.003643  0.000637 -5.714943  1.097406e-08 -0.004892 -0.002394"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#####################\n",
    "# LASSO with exog\n",
    "#####################\n",
    "\n",
    "obj_dml_data = dml.DoubleMLData(data_filtered, y_col=dependent[0], d_cols=endog, z_cols=instruments) #, x_cols=exog\n",
    "\n",
    "# For Lasso\n",
    "#learner_lasso = Lasso(alpha=0.1, max_iter=1000)\n",
    "learner_lasso = make_pipeline(StandardScaler(), Lasso(alpha=0.1, max_iter=1000))\n",
    "\n",
    "ml_l_lasso = clone(learner_lasso)\n",
    "ml_m_lasso = clone(learner_lasso)\n",
    "ml_r_lasso = clone(learner_lasso)\n",
    "\n",
    "# For Lasso\n",
    "dml_pliv_obj_lasso = dml.DoubleMLPLIV(obj_dml_data, ml_l_lasso, ml_m_lasso, ml_r_lasso)\n",
    "dml_pliv_obj_lasso.fit().summary  # Fit and show summary for Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merging results to an excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- success! ----\n"
     ]
    }
   ],
   "source": [
    "######### One coefficient\n",
    "\n",
    "list_of_results = []\n",
    "\n",
    "list_of_results.append([lasso_results, random_forest_results, gradient_boosting_results])\n",
    "    \n",
    "    \n",
    "# Flatten the list of lists\n",
    "flat_list = [item for sublist in list_of_results for item in sublist]\n",
    "\n",
    "# Convert the flattened list into a DataFrame\n",
    "df_results = pd.DataFrame(flat_list)\n",
    "\n",
    "df_results.to_excel(\n",
    "    \"/Users/gabrieldiasmp/Documents/pasta_gabriel/codigo/master_thesis/data/results_angrist_dml_noinstitutions.xlsx\",\n",
    "    index=False\n",
    ")\n",
    "print(\"----- success! ----\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- success! ----\n"
     ]
    }
   ],
   "source": [
    "########## Multiple endogneous variables\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df_combined = pd.concat([random_forest_results, gradient_boosting_results, lasso_results], ignore_index=True)\n",
    "\n",
    "\n",
    "df_combined.to_excel(\n",
    "    \"/Users/gabrieldiasmp/Documents/pasta_gabriel/codigo/master_thesis/data/results_angrist_dml_withinstitutions.xlsx\",\n",
    "    index=False\n",
    ")\n",
    "print(\"----- success! ----\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ClusteredData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dml_data = dml.DoubleMLClusterData(data_filtered, y_col=dependent[0], x_cols=exog, d_cols=endog, z_cols=instruments, cluster_cols='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lnf_lf1</th>\n",
       "      <td>0.045619</td>\n",
       "      <td>0.013246</td>\n",
       "      <td>3.443913</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.019657</td>\n",
       "      <td>0.071581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef   std err         t     P>|t|     2.5 %    97.5 %\n",
       "lnf_lf1  0.045619  0.013246  3.443913  0.000573  0.019657  0.071581"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# GRADIENT BOOSTING with exog\n",
    "#####################\n",
    "\n",
    "learner_boosting = GradientBoostingRegressor(n_estimators=100, max_depth=20, learning_rate=0.01)\n",
    "\n",
    "ml_l_boosting = clone(learner_boosting)\n",
    "ml_m_boosting = clone(learner_boosting)\n",
    "ml_r_boosting = clone(learner_boosting)\n",
    "\n",
    "# For boosting\n",
    "dml_pliv_obj_boosting = dml.DoubleMLPLIV(obj_dml_data, ml_l_boosting, ml_m_boosting, ml_r_boosting)\n",
    "\n",
    "# # Define the parameter grids for hyperparameter tuning\n",
    "# par_grids = {'ml_l': {'n_estimators': [50, 100, 200],\n",
    "#                       'max_depth': [10, 15, 20, 25],\n",
    "#                       'learning_rate': [0.01, 0.05, 0.1]},\n",
    "#              'ml_m': {'n_estimators': [50, 100, 200],\n",
    "#                       'max_depth': [10, 15, 20, 25],\n",
    "#                       'learning_rate': [0.01, 0.05, 0.1]},\n",
    "#              'ml_r': {'n_estimators': [50, 100, 200],\n",
    "#                       'max_depth': [10, 15, 20, 25],\n",
    "#                       'learning_rate': [0.01, 0.05, 0.1]}}\n",
    "\n",
    "# # Perform hyperparameter tuning\n",
    "# dml_pliv_obj_boosting.tune(par_grids, search_mode='grid_search')\n",
    "\n",
    "dml_pliv_obj_boosting.fit().summary  # Fit and show summary for boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lnf_lf1</th>\n",
       "      <td>0.066134</td>\n",
       "      <td>0.018179</td>\n",
       "      <td>3.637826</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.030503</td>\n",
       "      <td>0.101765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef   std err         t     P>|t|     2.5 %    97.5 %\n",
       "lnf_lf1  0.066134  0.018179  3.637826  0.000275  0.030503  0.101765"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# RANDOM FOREST with exog\n",
    "#####################\n",
    "\n",
    "learner = RandomForestRegressor(n_estimators=100, max_features=20, max_depth=15, min_samples_leaf=2)\n",
    "ml_l = clone(learner)\n",
    "ml_m = clone(learner)\n",
    "ml_r = clone(learner)\n",
    "\n",
    "dml_pliv_obj_rf = dml.DoubleMLPLIV(obj_dml_data, ml_l, ml_m, ml_r)\n",
    "\n",
    "# # Define the parameter grids for hyperparameter tuning\n",
    "# par_grids_rf = {'ml_l': {'n_estimators': [50, 100, 200],\n",
    "#                       'max_features': [5, 10, 15, 20],\n",
    "#                       'max_depth': [10, 15, 20, 25],\n",
    "#                       'min_samples_leaf': [1, 2, 4]},\n",
    "#              'ml_m': {'n_estimators': [50, 100, 200],\n",
    "#                       'max_features': [5, 10, 15, 20],\n",
    "#                       'max_depth': [10, 15, 20, 25],\n",
    "#                       'min_samples_leaf': [1, 2, 4]},\n",
    "#              'ml_r': {'n_estimators': [50, 100, 200],\n",
    "#                       'max_features': [5, 10, 15, 20],\n",
    "#                       'max_depth': [10, 15, 20, 25],\n",
    "#                       'min_samples_leaf': [1, 2, 4]}}\n",
    "\n",
    "# # Perform hyperparameter tuning\n",
    "# dml_pliv_obj_rf.tune(par_grids_rf, search_mode='grid_search')\n",
    "\n",
    "dml_pliv_obj_rf.fit().summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_without_is = [i for i in country if i not in [\"is\", 'ch', 'lu', 'gr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lnf_lf1']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu_immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lne_p ~ 1 + be + dk + de91 + de_91 + es + fr + ie + it + nl + at + pt + fi + se + uk + no + lneu_lf1 + d84 + d85 + d86 + d87 + d88 + d89 + d90 + d91 + d92 + d93 + d94 + d95 + d96 + d97 + d98 + d99 + [lnf_lf1  ~ nbosds12+ noward12+ nkosds12+ nbos_ep+ nowar_ep+ nkos_ep+ nbos_ls+ nowar_ls+ nkos_ls+ nbos_rr+ nowar_rr+ nkos_rr+ be+ dk+ de91+ de_91+ es+ fr+ ie+ it+ nl+ at+ pt+ fi+ se+ uk+ no+ lneu_lf1+ d84+ d85+ d86+ d87+ d88+ d89+ d90+ d91+ d92+ d93+ d94+ d95+ d96+ d97+ d98+ d99]\n"
     ]
    }
   ],
   "source": [
    "#Build the dependent variable column\n",
    "y_dependent = data_filtered[dependent]\n",
    "\n",
    "#endogenous variables\n",
    "x_endog = data_filtered[endog]\n",
    "\n",
    "# exogenous variables\n",
    "x_exog = data_filtered[exog] \n",
    "\n",
    "#Build out the instruments matrix. Statsmodels requires this matrix to contain not only all the\n",
    "# instruments but also the variables in exog that will NOT be instrumented\n",
    "#instruments = data_filtered[years + inst3b] #+ country + ['dold'] #WORKING!!!\n",
    "z_instruments = data_filtered[instruments] #+ country + ['dold'] #WORKING!!! #[\"nowarpr1\",\"nbospr1\",\"nkospr1\"]\n",
    "\n",
    "#### WORKING\n",
    "# Define the IV regression formula with multiple endogenous variables\n",
    "formula = ('lne_p ~ 1 + ' + ' + '.join(exog) + ' + ' +\n",
    "           '[lnf_lf1  ~ ' + '+ '.join(instruments) +  ']') #+ dold\n",
    "\n",
    "###### THE PROBLEM IS WITH THE COUNTRY\n",
    "# Define the IV regression formula with multiple endogenous variables\n",
    "# formula = ('lne_p ~ 1 + ' + ' + '.join(exog) + ' + ' +\n",
    "#            '[lnf_lf1  ~ ' + '+ '.join(inst3b) + '+' + ' + '.join(years) +  '+' + ' + '.join(country) + ']') #+ dold\n",
    "\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and train the IV2SLS model\n",
    "iv2sls_model = IV2SLS(dependent=y_dependent, endog=x_endog, exog=sm.add_constant(x_exog), instruments=z_instruments)\n",
    "iv2sls_model_results = iv2sls_model.fit()\n",
    "\n",
    "#Print the training summary\n",
    "print(iv2sls_model_results.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the IV regression model\n",
    "results = IV2SLS.from_formula(formula, data=data_filtered).fit()\n",
    "\n",
    "print(results.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Working instruments in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lne_p ~ 1 + NEU_ls + NEU_ep + NEU_rr + [lnf_lf1  ~ nbosds12+ noward12+ nkosds12+ nbos_ep+ nowar_ep+ nkos_ep+ nbos_ls+ nowar_ls+ nkos_ls+ nbos_rr+ nowar_rr+ nkos_rr+lneu_lf1 + d84 + d85 + d86 + d87 + d88 + d89 + d90 + d91 + d92 + d93 + d94 + d95 + d96 + d97 + d98 + d99]\n"
     ]
    }
   ],
   "source": [
    "#Build the dependent variable column\n",
    "dependent = data_filtered[['lne_p']]\n",
    "\n",
    "#endogenous variables\n",
    "endog = data_filtered[['lnf_lf1']]\n",
    "\n",
    "# exogenous variables\n",
    "exog = data_filtered[['NEU_ls', 'NEU_ep', 'NEU_rr']] \n",
    "\n",
    "#Build out the instruments matrix. Statsmodels requires this matrix to contain not only all the\n",
    "# instruments but also the variables in exog that will NOT be instrumented\n",
    "instruments = data_filtered[years + inst3b] #+ country + ['dold']\n",
    "\n",
    "# # # Define the IV regression formula with multiple endogenous variables\n",
    "# formula = ('lne_p ~ 1 + ' + ' + '.join(exog) + ' + ' +\n",
    "#            '[lnf_lf1  ~ ' + ' + '.join(years[3:]) + ' + ' + ' + '.join(country[2:]) +  ' + ' + ' + '.join(inst3b[2:]) + ']') #+ dold\n",
    "\n",
    "#### WORKING\n",
    "# Define the IV regression formula with multiple endogenous variables\n",
    "formula = ('lne_p ~ 1 + ' + ' + '.join(exog) + ' + ' +\n",
    "           '[lnf_lf1  ~ ' + '+ '.join(inst3b) + '+' + ' + '.join(years) +  ']') #+ dold\n",
    "\n",
    "###### THE PROBLEM IS WITH THE COUNTRY\n",
    "# Define the IV regression formula with multiple endogenous variables\n",
    "# formula = ('lne_p ~ 1 + ' + ' + '.join(exog) + ' + ' +\n",
    "#            '[lnf_lf1  ~ ' + '+ '.join(inst3b) + '+' + ' + '.join(years) +  '+' + ' + '.join(country) + ']') #+ dold\n",
    "\n",
    "print(formula)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  lne_p   R-squared:                      0.4264\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.4194\n",
      "No. Observations:                 334   F-statistic:                    185.90\n",
      "Date:                Tue, Apr 23 2024   P-value (F-stat)                0.0000\n",
      "Time:                        18:02:53   Distribution:                  chi2(4)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.0805     0.0208    -3.8770     0.0001     -0.1211     -0.0398\n",
      "NEU_ls         0.0038     0.0010     3.6419     0.0003      0.0017      0.0058\n",
      "NEU_ep         0.0002     0.0009     0.1652     0.8688     -0.0017      0.0020\n",
      "NEU_rr        -0.0036     0.0005    -7.0169     0.0000     -0.0046     -0.0026\n",
      "lnf_lf1        0.0295     0.0051     5.8271     0.0000      0.0196      0.0394\n",
      "==============================================================================\n",
      "\n",
      "Endogenous: lnf_lf1\n",
      "Instruments: nbosds12, noward12, nkosds12, nbos_ep, nowar_ep, nkos_ep, nbos_ls, nowar_ls, nkos_ls, nbos_rr, nowar_rr, nkos_rr, lneu_lf1, d84, d85, d86, d87, d88, d89, d90, d91, d92, d93, d94, d95, d96, d97, d98, d99\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "# Fit the IV regression model\n",
    "results = IV2SLS.from_formula(formula, data=data_filtered).fit()\n",
    "\n",
    "print(results.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  lne_p   R-squared:                      0.4267\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.4197\n",
      "No. Observations:                 334   F-statistic:                    184.17\n",
      "Date:                Tue, Apr 23 2024   P-value (F-stat)                0.0000\n",
      "Time:                        17:09:04   Distribution:                  chi2(4)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0860     0.0213    -4.0461     0.0001     -0.1277     -0.0444\n",
      "NEU_ls         0.0039     0.0010     3.8495     0.0001      0.0019      0.0059\n",
      "NEU_ep      2.162e-05     0.0009     0.0240     0.9809     -0.0017      0.0018\n",
      "NEU_rr        -0.0036     0.0005    -7.1971     0.0000     -0.0046     -0.0026\n",
      "lnf_lf1        0.0281     0.0052     5.4195     0.0000      0.0180      0.0383\n",
      "==============================================================================\n",
      "\n",
      "Endogenous: lnf_lf1\n",
      "Instruments: lneu_lf1, d84, d85, d86, d87, d88, d89, d90, d91, d92, d93, d94, d95, d96, d97, d98, d99, nowarpr1, nbospr1, nkospr1\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "#Build and train the IV2SLS model\n",
    "iv2sls_model = IV2SLS(dependent=dependent, endog=endog, exog=sm.add_constant(exog), instruments=instruments)\n",
    "iv2sls_model_results = iv2sls_model.fit()\n",
    "\n",
    "#Print the training summary\n",
    "print(iv2sls_model_results.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between 2022-06-30 and 2022-12-29 is 182 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "# Define the dates\n",
    "date1 = date(2022, 6, 30)\n",
    "date2 = date(2022, 12, 29)\n",
    "\n",
    "# Calculate the difference\n",
    "difference = date2 - date1\n",
    "\n",
    "# Extract days from the difference\n",
    "days_difference = difference.days\n",
    "\n",
    "# Print the result\n",
    "print(f\"The difference between {date1} and {date2} is {days_difference} days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration by Peri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth = pd.read_excel(\"../data/barro_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'Outcome'\n",
    "W = growth.drop(['Outcome', 'intercept', 'gdpsh465'], axis=1).columns.tolist()\n",
    "D = ['gdpsh465']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>2.5 %</th>\n",
       "      <th>97.5 %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gdpsh465</th>\n",
       "      <td>-0.011365</td>\n",
       "      <td>0.009281</td>\n",
       "      <td>-1.224466</td>\n",
       "      <td>0.220777</td>\n",
       "      <td>-0.029556</td>\n",
       "      <td>0.006826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              coef   std err         t     P>|t|     2.5 %    97.5 %\n",
       "gdpsh465 -0.011365  0.009281 -1.224466  0.220777 -0.029556  0.006826"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# GRADIENT BOOSTING with exog\n",
    "#####################\n",
    "\n",
    "obj_dml_data = dml.DoubleMLData(growth, y_col=y, x_cols=W, d_cols=D) #x_cols=exog, \n",
    "\n",
    "learner_boosting = GradientBoostingRegressor(n_estimators=100, max_depth=15, learning_rate=0.008)\n",
    "\n",
    "ml_g_boosting = clone(learner_boosting)\n",
    "ml_m_boosting = clone(learner_boosting)\n",
    "\n",
    "# For boosting\n",
    "dml_pliv_obj_boosting = dml.DoubleMLPLR(obj_dml_data, ml_g_boosting, ml_m_boosting)\n",
    "dml_pliv_obj_boosting.fit().summary  # Fit and show summary for boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml.DoubleMLPLR()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
